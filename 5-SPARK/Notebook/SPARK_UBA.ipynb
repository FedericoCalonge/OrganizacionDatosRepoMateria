{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SPARK_UBA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FedericoCalonge/OrganizacionDatosRepoMateria/blob/master/5-SPARK/Notebook/SPARK_UBA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRxHlLY88tcD",
        "colab_type": "text"
      },
      "source": [
        "# 1-Inicio SPARK y Lectura de datos.\n",
        "\n",
        "Vamos a ver cómo leer datos de un archivo con Spark y como hacerlo mediante transformaciones y acciones. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHdU05jEP1EY",
        "colab_type": "text"
      },
      "source": [
        "## Instalamos e importamos librerías"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnV5re322Wz9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 846
        },
        "outputId": "78b22306-6559-4fee-ffee-7e0f9c72db82"
      },
      "source": [
        "!pip install pyspark\n",
        "!pip install -U -q PyDrive\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/b0/bf9020b56492281b9c9d8aae8f44ff51e1bc91b3ef5a884385cb4e389a40/pyspark-3.0.0.tar.gz (204.7MB)\n",
            "\u001b[K     |████████████████████████████████| 204.7MB 62kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 40.4MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.0.0-py2.py3-none-any.whl size=205044182 sha256=ac13f6e8dc3e354723a91dbafcc6f1f05b90d14a5fd52dc35b481a06ee268ff5\n",
            "  Stored in directory: /root/.cache/pip/wheels/57/27/4d/ddacf7143f8d5b76c45c61ee2e43d9f8492fc5a8e78ebd7d37\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.0.0\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  openjdk-8-jre-headless\n",
            "Suggested packages:\n",
            "  openjdk-8-demo openjdk-8-source libnss-mdns fonts-dejavu-extra\n",
            "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
            "  fonts-wqy-zenhei fonts-indic\n",
            "The following NEW packages will be installed:\n",
            "  openjdk-8-jdk-headless openjdk-8-jre-headless\n",
            "0 upgraded, 2 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 35.8 MB of archives.\n",
            "After this operation, 140 MB of additional disk space will be used.\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "(Reading database ... 144465 files and directories currently installed.)\n",
            "Preparing to unpack .../openjdk-8-jre-headless_8u252-b09-1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u252-b09-1~18.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jdk-headless_8u252-b09-1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u252-b09-1~18.04) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u252-b09-1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u252-b09-1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhYIAjti3iaf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SQLContext\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xlsys9XvQHGK",
        "colab_type": "text"
      },
      "source": [
        "## Autenticamos con Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmVhF9Pi3mbH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Esto lo hacemos para poder bajar archivos de Google Drive.\n",
        "#Tenemos que entrar al link y colocar el código de verificación.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFdCQedFL7Z0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "e83a7161-80d0-4254-a075-e428c94821f4"
      },
      "source": [
        "#Esto es por si queremos montar nuestra Carpeta de Google al directorio de Files que vemos a la izquierda en el ícono \"Archivos/Files\" \n",
        "#(para así poder guardar o cargar archivos desde ahí).\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jjZsgQTOPgm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "3b89b520-d863-4683-bef0-ac2d6703d12b"
      },
      "source": [
        "!ls \"/content/drive/My Drive\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Backups Obligatorios Sincronizados'\n",
            "'Colab Notebooks'\n",
            " ContinuacionDjangoCurso4.rar\n",
            "'CSVs TP1-OrgaDeDatos'\n",
            "'Documento sin título.gdoc'\n",
            "'Grupo Tecnico IA'\n",
            "'HTML - CSS - BOOTSTRAP - PYTHONDJANGO.rar'\n",
            "'TL4 Ejemplos'\n",
            "'TP1 - Organizacion de Datos - Undav_Team'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qZCCf99QPGn",
        "colab_type": "text"
      },
      "source": [
        "## Bajamos archivo con la colección de Shakespeare y lo colocamos en la carpeta especificada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoqqUqNV3wFZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "b4e8fc47-6621-488f-fb9b-fc42e3614cf3"
      },
      "source": [
        "#ARREGLAR ESTO. Al parecer cuando hice arriba el moun drive me tiró este error. VERLO Y DESPUES VER COMO ACCEDER AL id '1ybtSQxrqVqbRrl_3FMzMYW03Flp4zM-j' EN EL NAVEGADOR.\n",
        "\n",
        "#Acá bajamos el archivo s.txt que son textos de Sheckspeare que vamos a usar más adelante para algunos ejemplos.\n",
        "downloaded = drive.CreateFile({'id':\"1ybtSQxrqVqbRrl_3FMzMYW03Flp4zM-j\"})   # Este es el ID del archivo que queremos tener acceso (que lo tiene el profe en su Drive).\n",
        "downloaded.GetContentFile(\"/content/drive/My Drive/Colab Notebooks/UBA/5-SPARK/Notebook/Txt Shekspeare utilizado/s.txt\")  #Este txt lo vemos a la izquierda yendo al ícono \"Archivos/Files\" y lo vemos en esa ruta que lo coloqué."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-2277f9dbfd76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Acá bajamos el archivo s.txt que son textos de Sheckspeare que vamos a usar más adelante para algunos ejemplos.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdownloaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCreateFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"1ybtSQxrqVqbRrl_3FMzMYW03Flp4zM-j\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# Este es el ID del archivo que queremos tener acceso (que lo tiene el profe en su Drive). DESPUES VER COMO ACCEDER A ESE EN EL NAVEGADOR.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdownloaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetContentFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/My Drive/Colab Notebooks/UBA/5-SPARK/Notebook/Txt Shekspeare utilizado/s.txt\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#Este txt lo vemos a la izquierda yendo al ícono \"Archivos/Files\" y lo vemos en esa ruta que lo coloqué.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'google.colab.drive' has no attribute 'CreateFile'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCKfIhFUQiyg",
        "colab_type": "text"
      },
      "source": [
        "## Creamos el Spark Context"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ENPglW_4Cco",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Tenemos que crear el \"Spark Context\" para poder trabajar con Spark. \n",
        "\n",
        "# 1ro creamos una sesión de Spark:\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "\n",
        "# Y luego de esta variable spark (nuestra sesión) obtenemos el contexto de Spark:\n",
        "sc = spark.sparkContext\n",
        "\n",
        "#Y esta variable, sc, es la que vamos a utilizar para comunicarnos con Spark."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68-dxCy6IqWv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "3c8906f6-cf77-412d-cff5-7ae0b6ec43f0"
      },
      "source": [
        "type(sc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.context.SparkContext"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CbdyUxRQuO1",
        "colab_type": "text"
      },
      "source": [
        "## Lectura de datos en Spark\n",
        "\n",
        "Vamos a ver cómo leer datos en Spark. \n",
        "Vamos a ver 3 formas de hacerlo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hsKVzAOJCNZ",
        "colab_type": "text"
      },
      "source": [
        "### Forma 1 - Paralelizando una coleccion de python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlaLdgdfI6Nm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "a0fbdcdc-ea72-45fc-ca5e-c768522f2458"
      },
      "source": [
        "#La idea de esta manera es tener una colección de datos en Python y paralelizarlos en un RDD con Spark.\n",
        "\n",
        "integersList = range(1,1001) ## Creamos una lista de entero del 1 al 1000 (no incluye al 1001).\n",
        "len(integersList)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cg31cLQYJQFP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "5760fa09-cb3b-48dd-8317-bcd14bea03d6"
      },
      "source": [
        "#Ahora para transformar esta variable de Python en un RDD lo que hacemos es llamar al método\n",
        "#parallelize (que es de sc, osea del Spark Context). Si ponemos el puntero del mouse sobre la función parallelize\n",
        "# nos tira la info de ese método. Nos dice que parallelize permite distribuir una colección de Python local\n",
        "#en un RDD, y el 2do parametro (slice, en el que pusimos 8) es la cantidad de particiones en que queremos que divida \n",
        "#Spark ese RDD.\n",
        "\n",
        "#De esta manera paralelizamos la coleccion utilizando 8 particiones o slices\n",
        "#Esta operacion es una transformacion de datos en un RDD. Y dado que Spark usa lazy evaluation, no corren jobs de Spark hasta el momento.\n",
        "\n",
        "integersListRDD = sc.parallelize(integersList, 8) #Entonces le pasamos la lista de enteros y le decimos que lo divida en 8 particiones. \n",
        "type(integersListRDD) #Entonces ahora en integersListRDD tenemos un RDD de Spark que podemos utilizarlo para luego procesarlo."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.rdd.PipelinedRDD"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YieMrEDJXEQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "32ea6755-582a-483c-9b91-3453daf44f6a"
      },
      "source": [
        "integersListRDD.getNumPartitions() #Para comprobar efectivamente que el RDD está dividido en 8 particiones (que fue lo que le indicamos cuando lo creamos)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3R9126T7JiA0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "381ecd9a-f74f-4abc-b3d2-46142461c04c"
      },
      "source": [
        "integersListRDD.toDebugString() #Método que nos permite llamar a un RDD que tenga transformaciones \n",
        "#para ver dichas transformaciones que se aplican en el RDD. Como en nuestro caso es un RDD que recién creamos solo\n",
        "#tenemos la operación de paralelización ('ParallelCollectionRDD'). "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'(8) PythonRDD[1] at RDD at PythonRDD.scala:53 []\\n |  ParallelCollectionRDD[0] at readRDDFromFile at PythonRDD.scala:262 []'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekG7ZqGOJm3-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bbc417a4-4f72-41cb-a009-be42f5a23abd"
      },
      "source": [
        "help(integersListRDD) #Para ver más métodos disponibles para utilizar en estructuras RDDs."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on PipelinedRDD in module pyspark.rdd object:\n",
            "\n",
            "class PipelinedRDD(RDD)\n",
            " |  Pipelined maps:\n",
            " |  \n",
            " |  >>> rdd = sc.parallelize([1, 2, 3, 4])\n",
            " |  >>> rdd.map(lambda x: 2 * x).cache().map(lambda x: 2 * x).collect()\n",
            " |  [4, 8, 12, 16]\n",
            " |  >>> rdd.map(lambda x: 2 * x).map(lambda x: 2 * x).collect()\n",
            " |  [4, 8, 12, 16]\n",
            " |  \n",
            " |  Pipelined reduces:\n",
            " |  >>> from operator import add\n",
            " |  >>> rdd.map(lambda x: 2 * x).reduce(add)\n",
            " |  20\n",
            " |  >>> rdd.flatMap(lambda x: [x, x]).reduce(add)\n",
            " |  20\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      PipelinedRDD\n",
            " |      RDD\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, prev, func, preservesPartitioning=False, isFromBarrier=False)\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  getNumPartitions(self)\n",
            " |      Returns the number of partitions in RDD\n",
            " |      \n",
            " |      >>> rdd = sc.parallelize([1, 2, 3, 4], 2)\n",
            " |      >>> rdd.getNumPartitions()\n",
            " |      2\n",
            " |  \n",
            " |  id(self)\n",
            " |      A unique ID for this RDD (within its SparkContext).\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from RDD:\n",
            " |  \n",
            " |  __add__(self, other)\n",
            " |      Return the union of this RDD and another one.\n",
            " |      \n",
            " |      >>> rdd = sc.parallelize([1, 1, 2, 3])\n",
            " |      >>> (rdd + rdd).collect()\n",
            " |      [1, 1, 2, 3, 1, 1, 2, 3]\n",
            " |  \n",
            " |  __getnewargs__(self)\n",
            " |  \n",
            " |  __repr__(self)\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  aggregate(self, zeroValue, seqOp, combOp)\n",
            " |      Aggregate the elements of each partition, and then the results for all\n",
            " |      the partitions, using a given combine functions and a neutral \"zero\n",
            " |      value.\"\n",
            " |      \n",
            " |      The functions ``op(t1, t2)`` is allowed to modify ``t1`` and return it\n",
            " |      as its result value to avoid object allocation; however, it should not\n",
            " |      modify ``t2``.\n",
            " |      \n",
            " |      The first function (seqOp) can return a different result type, U, than\n",
            " |      the type of this RDD. Thus, we need one operation for merging a T into\n",
            " |      an U and one operation for merging two U\n",
            " |      \n",
            " |      >>> seqOp = (lambda x, y: (x[0] + y, x[1] + 1))\n",
            " |      >>> combOp = (lambda x, y: (x[0] + y[0], x[1] + y[1]))\n",
            " |      >>> sc.parallelize([1, 2, 3, 4]).aggregate((0, 0), seqOp, combOp)\n",
            " |      (10, 4)\n",
            " |      >>> sc.parallelize([]).aggregate((0, 0), seqOp, combOp)\n",
            " |      (0, 0)\n",
            " |  \n",
            " |  aggregateByKey(self, zeroValue, seqFunc, combFunc, numPartitions=None, partitionFunc=<function portable_hash at 0x7ff515edfe18>)\n",
            " |      Aggregate the values of each key, using given combine functions and a neutral\n",
            " |      \"zero value\". This function can return a different result type, U, than the type\n",
            " |      of the values in this RDD, V. Thus, we need one operation for merging a V into\n",
            " |      a U and one operation for merging two U's, The former operation is used for merging\n",
            " |      values within a partition, and the latter is used for merging values between\n",
            " |      partitions. To avoid memory allocation, both of these functions are\n",
            " |      allowed to modify and return their first argument instead of creating a new U.\n",
            " |  \n",
            " |  barrier(self)\n",
            " |      .. note:: Experimental\n",
            " |      \n",
            " |      Marks the current stage as a barrier stage, where Spark must launch all tasks together.\n",
            " |      In case of a task failure, instead of only restarting the failed task, Spark will abort the\n",
            " |      entire stage and relaunch all tasks for this stage.\n",
            " |      The barrier execution mode feature is experimental and it only handles limited scenarios.\n",
            " |      Please read the linked SPIP and design docs to understand the limitations and future plans.\n",
            " |      \n",
            " |      :return: an :class:`RDDBarrier` instance that provides actions within a barrier stage.\n",
            " |      \n",
            " |      .. seealso:: :class:`BarrierTaskContext`\n",
            " |      .. seealso:: `SPIP: Barrier Execution Mode\n",
            " |          <http://jira.apache.org/jira/browse/SPARK-24374>`_\n",
            " |      .. seealso:: `Design Doc <https://jira.apache.org/jira/browse/SPARK-24582>`_\n",
            " |      \n",
            " |      .. versionadded:: 2.4.0\n",
            " |  \n",
            " |  cache(self)\n",
            " |      Persist this RDD with the default storage level (`MEMORY_ONLY`).\n",
            " |  \n",
            " |  cartesian(self, other)\n",
            " |      Return the Cartesian product of this RDD and another one, that is, the\n",
            " |      RDD of all pairs of elements ``(a, b)`` where ``a`` is in `self` and\n",
            " |      ``b`` is in `other`.\n",
            " |      \n",
            " |      >>> rdd = sc.parallelize([1, 2])\n",
            " |      >>> sorted(rdd.cartesian(rdd).collect())\n",
            " |      [(1, 1), (1, 2), (2, 1), (2, 2)]\n",
            " |  \n",
            " |  checkpoint(self)\n",
            " |      Mark this RDD for checkpointing. It will be saved to a file inside the\n",
            " |      checkpoint directory set with :meth:`SparkContext.setCheckpointDir` and\n",
            " |      all references to its parent RDDs will be removed. This function must\n",
            " |      be called before any job has been executed on this RDD. It is strongly\n",
            " |      recommended that this RDD is persisted in memory, otherwise saving it\n",
            " |      on a file will require recomputation.\n",
            " |  \n",
            " |  coalesce(self, numPartitions, shuffle=False)\n",
            " |      Return a new RDD that is reduced into `numPartitions` partitions.\n",
            " |      \n",
            " |      >>> sc.parallelize([1, 2, 3, 4, 5], 3).glom().collect()\n",
            " |      [[1], [2, 3], [4, 5]]\n",
            " |      >>> sc.parallelize([1, 2, 3, 4, 5], 3).coalesce(1).glom().collect()\n",
            " |      [[1, 2, 3, 4, 5]]\n",
            " |  \n",
            " |  cogroup(self, other, numPartitions=None)\n",
            " |      For each key k in `self` or `other`, return a resulting RDD that\n",
            " |      contains a tuple with the list of values for that key in `self` as\n",
            " |      well as `other`.\n",
            " |      \n",
            " |      >>> x = sc.parallelize([(\"a\", 1), (\"b\", 4)])\n",
            " |      >>> y = sc.parallelize([(\"a\", 2)])\n",
            " |      >>> [(x, tuple(map(list, y))) for x, y in sorted(list(x.cogroup(y).collect()))]\n",
            " |      [('a', ([1], [2])), ('b', ([4], []))]\n",
            " |  \n",
            " |  collect(self)\n",
            " |      Return a list that contains all of the elements in this RDD.\n",
            " |      \n",
            " |      .. note:: This method should only be used if the resulting array is expected\n",
            " |          to be small, as all the data is loaded into the driver's memory.\n",
            " |  \n",
            " |  collectAsMap(self)\n",
            " |      Return the key-value pairs in this RDD to the master as a dictionary.\n",
            " |      \n",
            " |      .. note:: this method should only be used if the resulting data is expected\n",
            " |          to be small, as all the data is loaded into the driver's memory.\n",
            " |      \n",
            " |      >>> m = sc.parallelize([(1, 2), (3, 4)]).collectAsMap()\n",
            " |      >>> m[1]\n",
            " |      2\n",
            " |      >>> m[3]\n",
            " |      4\n",
            " |  \n",
            " |  collectWithJobGroup(self, groupId, description, interruptOnCancel=False)\n",
            " |      .. note:: Experimental\n",
            " |      \n",
            " |      When collect rdd, use this method to specify job group.\n",
            " |      \n",
            " |      .. versionadded:: 3.0.0\n",
            " |  \n",
            " |  combineByKey(self, createCombiner, mergeValue, mergeCombiners, numPartitions=None, partitionFunc=<function portable_hash at 0x7ff515edfe18>)\n",
            " |      Generic function to combine the elements for each key using a custom\n",
            " |      set of aggregation functions.\n",
            " |      \n",
            " |      Turns an RDD[(K, V)] into a result of type RDD[(K, C)], for a \"combined\n",
            " |      type\" C.\n",
            " |      \n",
            " |      Users provide three functions:\n",
            " |      \n",
            " |          - `createCombiner`, which turns a V into a C (e.g., creates\n",
            " |            a one-element list)\n",
            " |          - `mergeValue`, to merge a V into a C (e.g., adds it to the end of\n",
            " |            a list)\n",
            " |          - `mergeCombiners`, to combine two C's into a single one (e.g., merges\n",
            " |            the lists)\n",
            " |      \n",
            " |      To avoid memory allocation, both mergeValue and mergeCombiners are allowed to\n",
            " |      modify and return their first argument instead of creating a new C.\n",
            " |      \n",
            " |      In addition, users can control the partitioning of the output RDD.\n",
            " |      \n",
            " |      .. note:: V and C can be different -- for example, one might group an RDD of type\n",
            " |          (Int, Int) into an RDD of type (Int, List[Int]).\n",
            " |      \n",
            " |      >>> x = sc.parallelize([(\"a\", 1), (\"b\", 1), (\"a\", 2)])\n",
            " |      >>> def to_list(a):\n",
            " |      ...     return [a]\n",
            " |      ...\n",
            " |      >>> def append(a, b):\n",
            " |      ...     a.append(b)\n",
            " |      ...     return a\n",
            " |      ...\n",
            " |      >>> def extend(a, b):\n",
            " |      ...     a.extend(b)\n",
            " |      ...     return a\n",
            " |      ...\n",
            " |      >>> sorted(x.combineByKey(to_list, append, extend).collect())\n",
            " |      [('a', [1, 2]), ('b', [1])]\n",
            " |  \n",
            " |  count(self)\n",
            " |      Return the number of elements in this RDD.\n",
            " |      \n",
            " |      >>> sc.parallelize([2, 3, 4]).count()\n",
            " |      3\n",
            " |  \n",
            " |  countApprox(self, timeout, confidence=0.95)\n",
            " |      Approximate version of count() that returns a potentially incomplete\n",
            " |      result within a timeout, even if not all tasks have finished.\n",
            " |      \n",
            " |      >>> rdd = sc.parallelize(range(1000), 10)\n",
            " |      >>> rdd.countApprox(1000, 1.0)\n",
            " |      1000\n",
            " |  \n",
            " |  countApproxDistinct(self, relativeSD=0.05)\n",
            " |      Return approximate number of distinct elements in the RDD.\n",
            " |      \n",
            " |      The algorithm used is based on streamlib's implementation of\n",
            " |      `\"HyperLogLog in Practice: Algorithmic Engineering of a State\n",
            " |      of The Art Cardinality Estimation Algorithm\", available here\n",
            " |      <https://doi.org/10.1145/2452376.2452456>`_.\n",
            " |      \n",
            " |      :param relativeSD: Relative accuracy. Smaller values create\n",
            " |                         counters that require more space.\n",
            " |                         It must be greater than 0.000017.\n",
            " |      \n",
            " |      >>> n = sc.parallelize(range(1000)).map(str).countApproxDistinct()\n",
            " |      >>> 900 < n < 1100\n",
            " |      True\n",
            " |      >>> n = sc.parallelize([i % 20 for i in range(1000)]).countApproxDistinct()\n",
            " |      >>> 16 < n < 24\n",
            " |      True\n",
            " |  \n",
            " |  countByKey(self)\n",
            " |      Count the number of elements for each key, and return the result to the\n",
            " |      master as a dictionary.\n",
            " |      \n",
            " |      >>> rdd = sc.parallelize([(\"a\", 1), (\"b\", 1), (\"a\", 1)])\n",
            " |      >>> sorted(rdd.countByKey().items())\n",
            " |      [('a', 2), ('b', 1)]\n",
            " |  \n",
            " |  countByValue(self)\n",
            " |      Return the count of each unique value in this RDD as a dictionary of\n",
            " |      (value, count) pairs.\n",
            " |      \n",
            " |      >>> sorted(sc.parallelize([1, 2, 1, 2, 2], 2).countByValue().items())\n",
            " |      [(1, 2), (2, 3)]\n",
            " |  \n",
            " |  distinct(self, numPartitions=None)\n",
            " |      Return a new RDD containing the distinct elements in this RDD.\n",
            " |      \n",
            " |      >>> sorted(sc.parallelize([1, 1, 2, 3]).distinct().collect())\n",
            " |      [1, 2, 3]\n",
            " |  \n",
            " |  filter(self, f)\n",
            " |      Return a new RDD containing only the elements that satisfy a predicate.\n",
            " |      \n",
            " |      >>> rdd = sc.parallelize([1, 2, 3, 4, 5])\n",
            " |      >>> rdd.filter(lambda x: x % 2 == 0).collect()\n",
            " |      [2, 4]\n",
            " |  \n",
            " |  first(self)\n",
            " |      Return the first element in this RDD.\n",
            " |      \n",
            " |      >>> sc.parallelize([2, 3, 4]).first()\n",
            " |      2\n",
            " |      >>> sc.parallelize([]).first()\n",
            " |      Traceback (most recent call last):\n",
            " |          ...\n",
            " |      ValueError: RDD is empty\n",
            " |  \n",
            " |  flatMap(self, f, preservesPartitioning=False)\n",
            " |      Return a new RDD by first applying a function to all elements of this\n",
            " |      RDD, and then flattening the results.\n",
            " |      \n",
            " |      >>> rdd = sc.parallelize([2, 3, 4])\n",
            " |      >>> sorted(rdd.flatMap(lambda x: range(1, x)).collect())\n",
            " |      [1, 1, 1, 2, 2, 3]\n",
            " |      >>> sorted(rdd.flatMap(lambda x: [(x, x), (x, x)]).collect())\n",
            " |      [(2, 2), (2, 2), (3, 3), (3, 3), (4, 4), (4, 4)]\n",
            " |  \n",
            " |  flatMapValues(self, f)\n",
            " |      Pass each value in the key-value pair RDD through a flatMap function\n",
            " |      without changing the keys; this also retains the original RDD's\n",
            " |      partitioning.\n",
            " |      \n",
            " |      >>> x = sc.parallelize([(\"a\", [\"x\", \"y\", \"z\"]), (\"b\", [\"p\", \"r\"])])\n",
            " |      >>> def f(x): return x\n",
            " |      >>> x.flatMapValues(f).collect()\n",
            " |      [('a', 'x'), ('a', 'y'), ('a', 'z'), ('b', 'p'), ('b', 'r')]\n",
            " |  \n",
            " |  fold(self, zeroValue, op)\n",
            " |      Aggregate the elements of each partition, and then the results for all\n",
            " |      the partitions, using a given associative function and a neutral \"zero value.\"\n",
            " |      \n",
            " |      The function ``op(t1, t2)`` is allowed to modify ``t1`` and return it\n",
            " |      as its result value to avoid object allocation; however, it should not\n",
            " |      modify ``t2``.\n",
            " |      \n",
            " |      This behaves somewhat differently from fold operations implemented\n",
            " |      for non-distributed collections in functional languages like Scala.\n",
            " |      This fold operation may be applied to partitions individually, and then\n",
            " |      fold those results into the final result, rather than apply the fold\n",
            " |      to each element sequentially in some defined ordering. For functions\n",
            " |      that are not commutative, the result may differ from that of a fold\n",
            " |      applied to a non-distributed collection.\n",
            " |      \n",
            " |      >>> from operator import add\n",
            " |      >>> sc.parallelize([1, 2, 3, 4, 5]).fold(0, add)\n",
            " |      15\n",
            " |  \n",
            " |  foldByKey(self, zeroValue, func, numPartitions=None, partitionFunc=<function portable_hash at 0x7ff515edfe18>)\n",
            " |      Merge the values for each key using an associative function \"func\"\n",
            " |      and a neutral \"zeroValue\" which may be added to the result an\n",
            " |      arbitrary number of times, and must not change the result\n",
            " |      (e.g., 0 for addition, or 1 for multiplication.).\n",
            " |      \n",
            " |      >>> rdd = sc.parallelize([(\"a\", 1), (\"b\", 1), (\"a\", 1)])\n",
            " |      >>> from operator import add\n",
            " |      >>> sorted(rdd.foldByKey(0, add).collect())\n",
            " |      [('a', 2), ('b', 1)]\n",
            " |  \n",
            " |  foreach(self, f)\n",
            " |      Applies a function to all elements of this RDD.\n",
            " |      \n",
            " |      >>> def f(x): print(x)\n",
            " |      >>> sc.parallelize([1, 2, 3, 4, 5]).foreach(f)\n",
            " |  \n",
            " |  foreachPartition(self, f)\n",
            " |      Applies a function to each partition of this RDD.\n",
            " |      \n",
            " |      >>> def f(iterator):\n",
            " |      ...     for x in iterator:\n",
            " |      ...          print(x)\n",
            " |      >>> sc.parallelize([1, 2, 3, 4, 5]).foreachPartition(f)\n",
            " |  \n",
            " |  fullOuterJoin(self, other, numPartitions=None)\n",
            " |      Perform a right outer join of `self` and `other`.\n",
            " |      \n",
            " |      For each element (k, v) in `self`, the resulting RDD will either\n",
            " |      contain all pairs (k, (v, w)) for w in `other`, or the pair\n",
            " |      (k, (v, None)) if no elements in `other` have key k.\n",
            " |      \n",
            " |      Similarly, for each element (k, w) in `other`, the resulting RDD will\n",
            " |      either contain all pairs (k, (v, w)) for v in `self`, or the pair\n",
            " |      (k, (None, w)) if no elements in `self` have key k.\n",
            " |      \n",
            " |      Hash-partitions the resulting RDD into the given number of partitions.\n",
            " |      \n",
            " |      >>> x = sc.parallelize([(\"a\", 1), (\"b\", 4)])\n",
            " |      >>> y = sc.parallelize([(\"a\", 2), (\"c\", 8)])\n",
            " |      >>> sorted(x.fullOuterJoin(y).collect())\n",
            " |      [('a', (1, 2)), ('b', (4, None)), ('c', (None, 8))]\n",
            " |  \n",
            " |  getCheckpointFile(self)\n",
            " |      Gets the name of the file to which this RDD was checkpointed\n",
            " |      \n",
            " |      Not defined if RDD is checkpointed locally.\n",
            " |  \n",
            " |  getStorageLevel(self)\n",
            " |      Get the RDD's current storage level.\n",
            " |      \n",
            " |      >>> rdd1 = sc.parallelize([1,2])\n",
            " |      >>> rdd1.getStorageLevel()\n",
            " |      StorageLevel(False, False, False, False, 1)\n",
            " |      >>> print(rdd1.getStorageLevel())\n",
            " |      Serialized 1x Replicated\n",
            " |  \n",
            " |  glom(self)\n",
            " |      Return an RDD created by coalescing all elements within each partition\n",
            " |      into a list.\n",
            " |      \n",
            " |      >>> rdd = sc.parallelize([1, 2, 3, 4], 2)\n",
            " |      >>> sorted(rdd.glom().collect())\n",
            " |      [[1, 2], [3, 4]]\n",
            " |  \n",
            " |  groupBy(self, f, numPartitions=None, partitionFunc=<function portable_hash at 0x7ff515edfe18>)\n",
            " |      Return an RDD of grouped items.\n",
            " |      \n",
            " |      >>> rdd = sc.parallelize([1, 1, 2, 3, 5, 8])\n",
            " |      >>> result = rdd.groupBy(lambda x: x % 2).collect()\n",
            " |      >>> sorted([(x, sorted(y)) for (x, y) in result])\n",
            " |      [(0, [2, 8]), (1, [1, 1, 3, 5])]\n",
            " |  \n",
            " |  groupByKey(self, numPartitions=None, partitionFunc=<function portable_hash at 0x7ff515edfe18>)\n",
            " |      Group the values for each key in the RDD into a single sequence.\n",
            " |      Hash-partitions the resulting RDD with numPartitions partitions.\n",
            " |      \n",
            " |      .. note:: If you are grouping in order to perform an aggregation (such as a\n",
            " |          sum or average) over each key, using reduceByKey or aggregateByKey will\n",
            " |          provide much better performance.\n",
            " |      \n",
            " |      >>> rdd = sc.parallelize([(\"a\", 1), (\"b\", 1), (\"a\", 1)])\n",
            " |      >>> sorted(rdd.groupByKey().mapValues(len).collect())\n",
            " |      [('a', 2), ('b', 1)]\n",
            " |      >>> sorted(rdd.groupByKey().mapValues(list).collect())\n",
            " |      [('a', [1, 1]), ('b', [1])]\n",
            " |  \n",
            " |  groupWith(self, other, *others)\n",
            " |      Alias for cogroup but with support for multiple RDDs.\n",
            " |      \n",
            " |      >>> w = sc.parallelize([(\"a\", 5), (\"b\", 6)])\n",
            " |      >>> x = sc.parallelize([(\"a\", 1), (\"b\", 4)])\n",
            " |      >>> y = sc.parallelize([(\"a\", 2)])\n",
            " |      >>> z = sc.parallelize([(\"b\", 42)])\n",
            " |      >>> [(x, tuple(map(list, y))) for x, y in sorted(list(w.groupWith(x, y, z).collect()))]\n",
            " |      [('a', ([5], [1], [2], [])), ('b', ([6], [4], [], [42]))]\n",
            " |  \n",
            " |  histogram(self, buckets)\n",
            " |      Compute a histogram using the provided buckets. The buckets\n",
            " |      are all open to the right except for the last which is closed.\n",
            " |      e.g. [1,10,20,50] means the buckets are [1,10) [10,20) [20,50],\n",
            " |      which means 1<=x<10, 10<=x<20, 20<=x<=50. And on the input of 1\n",
            " |      and 50 we would have a histogram of 1,0,1.\n",
            " |      \n",
            " |      If your histogram is evenly spaced (e.g. [0, 10, 20, 30]),\n",
            " |      this can be switched from an O(log n) inseration to O(1) per\n",
            " |      element (where n is the number of buckets).\n",
            " |      \n",
            " |      Buckets must be sorted, not contain any duplicates, and have\n",
            " |      at least two elements.\n",
            " |      \n",
            " |      If `buckets` is a number, it will generate buckets which are\n",
            " |      evenly spaced between the minimum and maximum of the RDD. For\n",
            " |      example, if the min value is 0 and the max is 100, given `buckets`\n",
            " |      as 2, the resulting buckets will be [0,50) [50,100]. `buckets` must\n",
            " |      be at least 1. An exception is raised if the RDD contains infinity.\n",
            " |      If the elements in the RDD do not vary (max == min), a single bucket\n",
            " |      will be used.\n",
            " |      \n",
            " |      The return value is a tuple of buckets and histogram.\n",
            " |      \n",
            " |      >>> rdd = sc.parallelize(range(51))\n",
            " |      >>> rdd.histogram(2)\n",
            " |      ([0, 25, 50], [25, 26])\n",
            " |      >>> rdd.histogram([0, 5, 25, 50])\n",
            " |      ([0, 5, 25, 50], [5, 20, 26])\n",
            " |      >>> rdd.histogram([0, 15, 30, 45, 60])  # evenly spaced buckets\n",
            " |      ([0, 15, 30, 45, 60], [15, 15, 15, 6])\n",
            " |      >>> rdd = sc.parallelize([\"ab\", \"ac\", \"b\", \"bd\", \"ef\"])\n",
            " |      >>> rdd.histogram((\"a\", \"b\", \"c\"))\n",
            " |      (('a', 'b', 'c'), [2, 2])\n",
            " |  \n",
            " |  intersection(self, other)\n",
            " |      Return the intersection of this RDD and another one. The output will\n",
            " |      not contain any duplicate elements, even if the input RDDs did.\n",
            " |      \n",
            " |      .. note:: This method performs a shuffle internally.\n",
            " |      \n",
            " |      >>> rdd1 = sc.parallelize([1, 10, 2, 3, 4, 5])\n",
            " |      >>> rdd2 = sc.parallelize([1, 6, 2, 3, 7, 8])\n",
            " |      >>> rdd1.intersection(rdd2).collect()\n",
            " |      [1, 2, 3]\n",
            " |  \n",
            " |  isCheckpointed(self)\n",
            " |      Return whether this RDD is checkpointed and materialized, either reliably or locally.\n",
            " |  \n",
            " |  isEmpty(self)\n",
            " |      Returns true if and only if the RDD contains no elements at all.\n",
            " |      \n",
            " |      .. note:: an RDD may be empty even when it has at least 1 partition.\n",
            " |      \n",
            " |      >>> sc.parallelize([]).isEmpty()\n",
            " |      True\n",
            " |      >>> sc.parallelize([1]).isEmpty()\n",
            " |      False\n",
            " |  \n",
            " |  isLocallyCheckpointed(self)\n",
            " |      Return whether this RDD is marked for local checkpointing.\n",
            " |      \n",
            " |      Exposed for testing.\n",
            " |  \n",
            " |  join(self, other, numPartitions=None)\n",
            " |      Return an RDD containing all pairs of elements with matching keys in\n",
            " |      `self` and `other`.\n",
            " |      \n",
            " |      Each pair of elements will be returned as a (k, (v1, v2)) tuple, where\n",
            " |      (k, v1) is in `self` and (k, v2) is in `other`.\n",
            " |      \n",
            " |      Performs a hash join across the cluster.\n",
            " |      \n",
            " |      >>> x = sc.parallelize([(\"a\", 1), (\"b\", 4)])\n",
            " |      >>> y = sc.parallelize([(\"a\", 2), (\"a\", 3)])\n",
            " |      >>> sorted(x.join(y).collect())\n",
            " |      [('a', (1, 2)), ('a', (1, 3))]\n",
            " |  \n",
            " |  keyBy(self, f)\n",
            " |      Creates tuples of the elements in this RDD by applying `f`.\n",
            " |      \n",
            " |      >>> x = sc.parallelize(range(0,3)).keyBy(lambda x: x*x)\n",
            " |      >>> y = sc.parallelize(zip(range(0,5), range(0,5)))\n",
            " |      >>> [(x, list(map(list, y))) for x, y in sorted(x.cogroup(y).collect())]\n",
            " |      [(0, [[0], [0]]), (1, [[1], [1]]), (2, [[], [2]]), (3, [[], [3]]), (4, [[2], [4]])]\n",
            " |  \n",
            " |  keys(self)\n",
            " |      Return an RDD with the keys of each tuple.\n",
            " |      \n",
            " |      >>> m = sc.parallelize([(1, 2), (3, 4)]).keys()\n",
            " |      >>> m.collect()\n",
            " |      [1, 3]\n",
            " |  \n",
            " |  leftOuterJoin(self, other, numPartitions=None)\n",
            " |      Perform a left outer join of `self` and `other`.\n",
            " |      \n",
            " |      For each element (k, v) in `self`, the resulting RDD will either\n",
            " |      contain all pairs (k, (v, w)) for w in `other`, or the pair\n",
            " |      (k, (v, None)) if no elements in `other` have key k.\n",
            " |      \n",
            " |      Hash-partitions the resulting RDD into the given number of partitions.\n",
            " |      \n",
            " |      >>> x = sc.parallelize([(\"a\", 1), (\"b\", 4)])\n",
            " |      >>> y = sc.parallelize([(\"a\", 2)])\n",
            " |      >>> sorted(x.leftOuterJoin(y).collect())\n",
            " |      [('a', (1, 2)), ('b', (4, None))]\n",
            " |  \n",
            " |  localCheckpoint(self)\n",
            " |      Mark this RDD for local checkpointing using Spark's existing caching layer.\n",
            " |      \n",
            " |      This method is for users who wish to truncate RDD lineages while skipping the expensive\n",
            " |      step of replicating the materialized data in a reliable distributed file system. This is\n",
            " |      useful for RDDs with long lineages that need to be truncated periodically (e.g. GraphX).\n",
            " |      \n",
            " |      Local checkpointing sacrifices fault-tolerance for performance. In particular, checkpointed\n",
            " |      data is written to ephemeral local storage in the executors instead of to a reliable,\n",
            " |      fault-tolerant storage. The effect is that if an executor fails during the computation,\n",
            " |      the checkpointed data may no longer be accessible, causing an irrecoverable job failure.\n",
            " |      \n",
            " |      This is NOT safe to use with dynamic allocation, which removes executors along\n",
            " |      with their cached blocks. If you must use both features, you are advised to set\n",
            " |      `spark.dynamicAllocation.cachedExecutorIdleTimeout` to a high value.\n",
            " |      \n",
            " |      The checkpoint directory set through :meth:`SparkContext.setCheckpointDir` is not used.\n",
            " |  \n",
            " |  lookup(self, key)\n",
            " |      Return the list of values in the RDD for key `key`. This operation\n",
            " |      is done efficiently if the RDD has a known partitioner by only\n",
            " |      searching the partition that the key maps to.\n",
            " |      \n",
            " |      >>> l = range(1000)\n",
            " |      >>> rdd = sc.parallelize(zip(l, l), 10)\n",
            " |      >>> rdd.lookup(42)  # slow\n",
            " |      [42]\n",
            " |      >>> sorted = rdd.sortByKey()\n",
            " |      >>> sorted.lookup(42)  # fast\n",
            " |      [42]\n",
            " |      >>> sorted.lookup(1024)\n",
            " |      []\n",
            " |      >>> rdd2 = sc.parallelize([(('a', 'b'), 'c')]).groupByKey()\n",
            " |      >>> list(rdd2.lookup(('a', 'b'))[0])\n",
            " |      ['c']\n",
            " |  \n",
            " |  map(self, f, preservesPartitioning=False)\n",
            " |      Return a new RDD by applying a function to each element of this RDD.\n",
            " |      \n",
            " |      >>> rdd = sc.parallelize([\"b\", \"a\", \"c\"])\n",
            " |      >>> sorted(rdd.map(lambda x: (x, 1)).collect())\n",
            " |      [('a', 1), ('b', 1), ('c', 1)]\n",
            " |  \n",
            " |  mapPartitions(self, f, preservesPartitioning=False)\n",
            " |      Return a new RDD by applying a function to each partition of this RDD.\n",
            " |      \n",
            " |      >>> rdd = sc.parallelize([1, 2, 3, 4], 2)\n",
            " |      >>> def f(iterator): yield sum(iterator)\n",
            " |      >>> rdd.mapPartitions(f).collect()\n",
            " |      [3, 7]\n",
            " |  \n",
            " |  mapPartitionsWithIndex(self, f, preservesPartitioning=False)\n",
            " |      Return a new RDD by applying a function to each partition of this RDD,\n",
            " |      while tracking the index of the original partition.\n",
            " |      \n",
            " |      >>> rdd = sc.parallelize([1, 2, 3, 4], 4)\n",
            " |      >>> def f(splitIndex, iterator): yield splitIndex\n",
            " |      >>> rdd.mapPartitionsWithIndex(f).sum()\n",
            " |      6\n",
            " |  \n",
            " |  mapPartitionsWithSplit(self, f, preservesPartitioning=False)\n",
            " |      Deprecated: use mapPartitionsWithIndex instead.\n",
            " |      \n",
            " |      Return a new RDD by applying a function to each partition of this RDD,\n",
            " |      while tracking the index of the original partition.\n",
            " |      \n",
            " |      >>> rdd = sc.parallelize([1, 2, 3, 4], 4)\n",
            " |      >>> def f(splitIndex, iterator): yield splitIndex\n",
            " |      >>> rdd.mapPartitionsWithSplit(f).sum()\n",
            " |      6\n",
            " |  \n",
            " |  mapValues(self, f)\n",
            " |      Pass each value in the key-value pair RDD through a map function\n",
            " |      without changing the keys; this also retains the original RDD's\n",
            " |      partitioning.\n",
            " |      \n",
            " |      >>> x = sc.parallelize([(\"a\", [\"apple\", \"banana\", \"lemon\"]), (\"b\", [\"grapes\"])])\n",
            " |      >>> def f(x): return len(x)\n",
            " |      >>> x.mapValues(f).collect()\n",
            " |      [('a', 3), ('b', 1)]\n",
            " |  \n",
            " |  max(self, key=None)\n",
            " |      Find the maximum item in this RDD.\n",
            " |      \n",
            " |      :param key: A function used to generate key for comparing\n",
            " |      \n",
            " |      >>> rdd = sc.parallelize([1.0, 5.0, 43.0, 10.0])\n",
            " |      >>> rdd.max()\n",
            " |      43.0\n",
            " |      >>> rdd.max(key=str)\n",
            " |      5.0\n",
            " |  \n",
            " |  mean(self)\n",
            " |      Compute the mean of this RDD's elements.\n",
            " |      \n",
            " |      >>> sc.parallelize([1, 2, 3]).mean()\n",
            " |      2.0\n",
            " |  \n",
            " |  meanApprox(self, timeout, confidence=0.95)\n",
            " |      Approximate operation to return the mean within a timeout\n",
            " |      or meet the confidence.\n",
            " |      \n",
            " |      >>> rdd = sc.parallelize(range(1000), 10)\n",
            " |      >>> r = sum(range(1000)) / 1000.0\n",
            " |      >>> abs(rdd.meanApprox(1000) - r) / r < 0.05\n",
            " |      True\n",
            " |  \n",
            " |  min(self, key=None)\n",
            " |      Find the minimum item in this RDD.\n",
            " |      \n",
            " |      :param key: A function used to generate key for comparing\n",
            " |      \n",
            " |      >>> rdd = sc.parallelize([2.0, 5.0, 43.0, 10.0])\n",
            " |      >>> rdd.min()\n",
            " |      2.0\n",
            " |      >>> rdd.min(key=str)\n",
            " |      10.0\n",
            " |  \n",
            " |  name(self)\n",
            " |      Return the name of this RDD.\n",
            " |  \n",
            " |  partitionBy(self, numPartitions, partitionFunc=<function portable_hash at 0x7ff515edfe18>)\n",
            " |      Return a copy of the RDD partitioned using the specified partitioner.\n",
            " |      \n",
            " |      >>> pairs = sc.parallelize([1, 2, 3, 4, 2, 4, 1]).map(lambda x: (x, x))\n",
            " |      >>> sets = pairs.partitionBy(2).glom().collect()\n",
            " |      >>> len(set(sets[0]).intersection(set(sets[1])))\n",
            " |      0\n",
            " |  \n",
            " |  persist(self, storageLevel=StorageLevel(False, True, False, False, 1))\n",
            " |      Set this RDD's storage level to persist its values across operations\n",
            " |      after the first time it is computed. This can only be used to assign\n",
            " |      a new storage level if the RDD does not have a storage level set yet.\n",
            " |      If no storage level is specified defaults to (`MEMORY_ONLY`).\n",
            " |      \n",
            " |      >>> rdd = sc.parallelize([\"b\", \"a\", \"c\"])\n",
            " |      >>> rdd.persist().is_cached\n",
            " |      True\n",
            " |  \n",
            " |  pipe(self, command, env=None, checkCode=False)\n",
            " |      Return an RDD created by piping elements to a forked external process.\n",
            " |      \n",
            " |      >>> sc.parallelize(['1', '2', '', '3']).pipe('cat').collect()\n",
            " |      ['1', '2', '', '3']\n",
            " |      \n",
            " |      :param checkCode: whether or not to check the return value of the shell command.\n",
            " |  \n",
            " |  randomSplit(self, weights, seed=None)\n",
            " |      Randomly splits this RDD with the provided weights.\n",
            " |      \n",
            " |      :param weights: weights for splits, will be normalized if they don't sum to 1\n",
            " |      :param seed: random seed\n",
            " |      :return: split RDDs in a list\n",
            " |      \n",
            " |      >>> rdd = sc.parallelize(range(500), 1)\n",
            " |      >>> rdd1, rdd2 = rdd.randomSplit([2, 3], 17)\n",
            " |      >>> len(rdd1.collect() + rdd2.collect())\n",
            " |      500\n",
            " |      >>> 150 < rdd1.count() < 250\n",
            " |      True\n",
            " |      >>> 250 < rdd2.count() < 350\n",
            " |      True\n",
            " |  \n",
            " |  reduce(self, f)\n",
            " |      Reduces the elements of this RDD using the specified commutative and\n",
            " |      associative binary operator. Currently reduces partitions locally.\n",
            " |      \n",
            " |      >>> from operator import add\n",
            " |      >>> sc.parallelize([1, 2, 3, 4, 5]).reduce(add)\n",
            " |      15\n",
            " |      >>> sc.parallelize((2 for _ in range(10))).map(lambda x: 1).cache().reduce(add)\n",
            " |      10\n",
            " |      >>> sc.parallelize([]).reduce(add)\n",
            " |      Traceback (most recent call last):\n",
            " |          ...\n",
            " |      ValueError: Can not reduce() empty RDD\n",
            " |  \n",
            " |  reduceByKey(self, func, numPartitions=None, partitionFunc=<function portable_hash at 0x7ff515edfe18>)\n",
            " |      Merge the values for each key using an associative and commutative reduce function.\n",
            " |      \n",
            " |      This will also perform the merging locally on each mapper before\n",
            " |      sending results to a reducer, similarly to a \"combiner\" in MapReduce.\n",
            " |      \n",
            " |      Output will be partitioned with `numPartitions` partitions, or\n",
            " |      the default parallelism level if `numPartitions` is not specified.\n",
            " |      Default partitioner is hash-partition.\n",
            " |      \n",
            " |      >>> from operator import add\n",
            " |      >>> rdd = sc.parallelize([(\"a\", 1), (\"b\", 1), (\"a\", 1)])\n",
            " |      >>> sorted(rdd.reduceByKey(add).collect())\n",
            " |      [('a', 2), ('b', 1)]\n",
            " |  \n",
            " |  reduceByKeyLocally(self, func)\n",
            " |      Merge the values for each key using an associative and commutative reduce function, but\n",
            " |      return the results immediately to the master as a dictionary.\n",
            " |      \n",
            " |      This will also perform the merging locally on each mapper before\n",
            " |      sending results to a reducer, similarly to a \"combiner\" in MapReduce.\n",
            " |      \n",
            " |      >>> from operator import add\n",
            " |      >>> rdd = sc.parallelize([(\"a\", 1), (\"b\", 1), (\"a\", 1)])\n",
            " |      >>> sorted(rdd.reduceByKeyLocally(add).items())\n",
            " |      [('a', 2), ('b', 1)]\n",
            " |  \n",
            " |  repartition(self, numPartitions)\n",
            " |      Return a new RDD that has exactly numPartitions partitions.\n",
            " |      \n",
            " |      Can increase or decrease the level of parallelism in this RDD.\n",
            " |      Internally, this uses a shuffle to redistribute data.\n",
            " |      If you are decreasing the number of partitions in this RDD, consider\n",
            " |      using `coalesce`, which can avoid performing a shuffle.\n",
            " |      \n",
            " |      >>> rdd = sc.parallelize([1,2,3,4,5,6,7], 4)\n",
            " |      >>> sorted(rdd.glom().collect())\n",
            " |      [[1], [2, 3], [4, 5], [6, 7]]\n",
            " |      >>> len(rdd.repartition(2).glom().collect())\n",
            " |      2\n",
            " |      >>> len(rdd.repartition(10).glom().collect())\n",
            " |      10\n",
            " |  \n",
            " |  repartitionAndSortWithinPartitions(self, numPartitions=None, partitionFunc=<function portable_hash at 0x7ff515edfe18>, ascending=True, keyfunc=<function RDD.<lambda> at 0x7ff5159be400>)\n",
            " |      Repartition the RDD according to the given partitioner and, within each resulting partition,\n",
            " |      sort records by their keys.\n",
            " |      \n",
            " |      >>> rdd = sc.parallelize([(0, 5), (3, 8), (2, 6), (0, 8), (3, 8), (1, 3)])\n",
            " |      >>> rdd2 = rdd.repartitionAndSortWithinPartitions(2, lambda x: x % 2, True)\n",
            " |      >>> rdd2.glom().collect()\n",
            " |      [[(0, 5), (0, 8), (2, 6)], [(1, 3), (3, 8), (3, 8)]]\n",
            " |  \n",
            " |  rightOuterJoin(self, other, numPartitions=None)\n",
            " |      Perform a right outer join of `self` and `other`.\n",
            " |      \n",
            " |      For each element (k, w) in `other`, the resulting RDD will either\n",
            " |      contain all pairs (k, (v, w)) for v in this, or the pair (k, (None, w))\n",
            " |      if no elements in `self` have key k.\n",
            " |      \n",
            " |      Hash-partitions the resulting RDD into the given number of partitions.\n",
            " |      \n",
            " |      >>> x = sc.parallelize([(\"a\", 1), (\"b\", 4)])\n",
            " |      >>> y = sc.parallelize([(\"a\", 2)])\n",
            " |      >>> sorted(y.rightOuterJoin(x).collect())\n",
            " |      [('a', (2, 1)), ('b', (None, 4))]\n",
            " |  \n",
            " |  sample(self, withReplacement, fraction, seed=None)\n",
            " |      Return a sampled subset of this RDD.\n",
            " |      \n",
            " |      :param withReplacement: can elements be sampled multiple times (replaced when sampled out)\n",
            " |      :param fraction: expected size of the sample as a fraction of this RDD's size\n",
            " |          without replacement: probability that each element is chosen; fraction must be [0, 1]\n",
            " |          with replacement: expected number of times each element is chosen; fraction must be >= 0\n",
            " |      :param seed: seed for the random number generator\n",
            " |      \n",
            " |      .. note:: This is not guaranteed to provide exactly the fraction specified of the total\n",
            " |          count of the given :class:`DataFrame`.\n",
            " |      \n",
            " |      >>> rdd = sc.parallelize(range(100), 4)\n",
            " |      >>> 6 <= rdd.sample(False, 0.1, 81).count() <= 14\n",
            " |      True\n",
            " |  \n",
            " |  sampleByKey(self, withReplacement, fractions, seed=None)\n",
            " |      Return a subset of this RDD sampled by key (via stratified sampling).\n",
            " |      Create a sample of this RDD using variable sampling rates for\n",
            " |      different keys as specified by fractions, a key to sampling rate map.\n",
            " |      \n",
            " |      >>> fractions = {\"a\": 0.2, \"b\": 0.1}\n",
            " |      >>> rdd = sc.parallelize(fractions.keys()).cartesian(sc.parallelize(range(0, 1000)))\n",
            " |      >>> sample = dict(rdd.sampleByKey(False, fractions, 2).groupByKey().collect())\n",
            " |      >>> 100 < len(sample[\"a\"]) < 300 and 50 < len(sample[\"b\"]) < 150\n",
            " |      True\n",
            " |      >>> max(sample[\"a\"]) <= 999 and min(sample[\"a\"]) >= 0\n",
            " |      True\n",
            " |      >>> max(sample[\"b\"]) <= 999 and min(sample[\"b\"]) >= 0\n",
            " |      True\n",
            " |  \n",
            " |  sampleStdev(self)\n",
            " |      Compute the sample standard deviation of this RDD's elements (which\n",
            " |      corrects for bias in estimating the standard deviation by dividing by\n",
            " |      N-1 instead of N).\n",
            " |      \n",
            " |      >>> sc.parallelize([1, 2, 3]).sampleStdev()\n",
            " |      1.0\n",
            " |  \n",
            " |  sampleVariance(self)\n",
            " |      Compute the sample variance of this RDD's elements (which corrects\n",
            " |      for bias in estimating the variance by dividing by N-1 instead of N).\n",
            " |      \n",
            " |      >>> sc.parallelize([1, 2, 3]).sampleVariance()\n",
            " |      1.0\n",
            " |  \n",
            " |  saveAsHadoopDataset(self, conf, keyConverter=None, valueConverter=None)\n",
            " |      Output a Python RDD of key-value pairs (of form ``RDD[(K, V)]``) to any Hadoop file\n",
            " |      system, using the old Hadoop OutputFormat API (mapred package). Keys/values are\n",
            " |      converted for output using either user specified converters or, by default,\n",
            " |      \"org.apache.spark.api.python.JavaToWritableConverter\".\n",
            " |      \n",
            " |      :param conf: Hadoop job configuration, passed in as a dict\n",
            " |      :param keyConverter: (None by default)\n",
            " |      :param valueConverter: (None by default)\n",
            " |  \n",
            " |  saveAsHadoopFile(self, path, outputFormatClass, keyClass=None, valueClass=None, keyConverter=None, valueConverter=None, conf=None, compressionCodecClass=None)\n",
            " |      Output a Python RDD of key-value pairs (of form ``RDD[(K, V)]``) to any Hadoop file\n",
            " |      system, using the old Hadoop OutputFormat API (mapred package). Key and value types\n",
            " |      will be inferred if not specified. Keys and values are converted for output using either\n",
            " |      user specified converters or \"org.apache.spark.api.python.JavaToWritableConverter\". The\n",
            " |      `conf` is applied on top of the base Hadoop conf associated with the SparkContext\n",
            " |      of this RDD to create a merged Hadoop MapReduce job configuration for saving the data.\n",
            " |      \n",
            " |      :param path: path to Hadoop file\n",
            " |      :param outputFormatClass: fully qualified classname of Hadoop OutputFormat\n",
            " |             (e.g. \"org.apache.hadoop.mapred.SequenceFileOutputFormat\")\n",
            " |      :param keyClass: fully qualified classname of key Writable class\n",
            " |             (e.g. \"org.apache.hadoop.io.IntWritable\", None by default)\n",
            " |      :param valueClass: fully qualified classname of value Writable class\n",
            " |             (e.g. \"org.apache.hadoop.io.Text\", None by default)\n",
            " |      :param keyConverter: (None by default)\n",
            " |      :param valueConverter: (None by default)\n",
            " |      :param conf: (None by default)\n",
            " |      :param compressionCodecClass: (None by default)\n",
            " |  \n",
            " |  saveAsNewAPIHadoopDataset(self, conf, keyConverter=None, valueConverter=None)\n",
            " |      Output a Python RDD of key-value pairs (of form ``RDD[(K, V)]``) to any Hadoop file\n",
            " |      system, using the new Hadoop OutputFormat API (mapreduce package). Keys/values are\n",
            " |      converted for output using either user specified converters or, by default,\n",
            " |      \"org.apache.spark.api.python.JavaToWritableConverter\".\n",
            " |      \n",
            " |      :param conf: Hadoop job configuration, passed in as a dict\n",
            " |      :param keyConverter: (None by default)\n",
            " |      :param valueConverter: (None by default)\n",
            " |  \n",
            " |  saveAsNewAPIHadoopFile(self, path, outputFormatClass, keyClass=None, valueClass=None, keyConverter=None, valueConverter=None, conf=None)\n",
            " |      Output a Python RDD of key-value pairs (of form ``RDD[(K, V)]``) to any Hadoop file\n",
            " |      system, using the new Hadoop OutputFormat API (mapreduce package). Key and value types\n",
            " |      will be inferred if not specified. Keys and values are converted for output using either\n",
            " |      user specified converters or \"org.apache.spark.api.python.JavaToWritableConverter\". The\n",
            " |      `conf` is applied on top of the base Hadoop conf associated with the SparkContext\n",
            " |      of this RDD to create a merged Hadoop MapReduce job configuration for saving the data.\n",
            " |      \n",
            " |      :param path: path to Hadoop file\n",
            " |      :param outputFormatClass: fully qualified classname of Hadoop OutputFormat\n",
            " |             (e.g. \"org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat\")\n",
            " |      :param keyClass: fully qualified classname of key Writable class\n",
            " |             (e.g. \"org.apache.hadoop.io.IntWritable\", None by default)\n",
            " |      :param valueClass: fully qualified classname of value Writable class\n",
            " |             (e.g. \"org.apache.hadoop.io.Text\", None by default)\n",
            " |      :param keyConverter: (None by default)\n",
            " |      :param valueConverter: (None by default)\n",
            " |      :param conf: Hadoop job configuration, passed in as a dict (None by default)\n",
            " |  \n",
            " |  saveAsPickleFile(self, path, batchSize=10)\n",
            " |      Save this RDD as a SequenceFile of serialized objects. The serializer\n",
            " |      used is :class:`pyspark.serializers.PickleSerializer`, default batch size\n",
            " |      is 10.\n",
            " |      \n",
            " |      >>> tmpFile = NamedTemporaryFile(delete=True)\n",
            " |      >>> tmpFile.close()\n",
            " |      >>> sc.parallelize([1, 2, 'spark', 'rdd']).saveAsPickleFile(tmpFile.name, 3)\n",
            " |      >>> sorted(sc.pickleFile(tmpFile.name, 5).map(str).collect())\n",
            " |      ['1', '2', 'rdd', 'spark']\n",
            " |  \n",
            " |  saveAsSequenceFile(self, path, compressionCodecClass=None)\n",
            " |      Output a Python RDD of key-value pairs (of form ``RDD[(K, V)]``) to any Hadoop file\n",
            " |      system, using the \"org.apache.hadoop.io.Writable\" types that we convert from the\n",
            " |      RDD's key and value types. The mechanism is as follows:\n",
            " |      \n",
            " |          1. Pyrolite is used to convert pickled Python RDD into RDD of Java objects.\n",
            " |          2. Keys and values of this Java RDD are converted to Writables and written out.\n",
            " |      \n",
            " |      :param path: path to sequence file\n",
            " |      :param compressionCodecClass: (None by default)\n",
            " |  \n",
            " |  saveAsTextFile(self, path, compressionCodecClass=None)\n",
            " |      Save this RDD as a text file, using string representations of elements.\n",
            " |      \n",
            " |      :param path: path to text file\n",
            " |      :param compressionCodecClass: (None by default) string i.e.\n",
            " |          \"org.apache.hadoop.io.compress.GzipCodec\"\n",
            " |      \n",
            " |      >>> tempFile = NamedTemporaryFile(delete=True)\n",
            " |      >>> tempFile.close()\n",
            " |      >>> sc.parallelize(range(10)).saveAsTextFile(tempFile.name)\n",
            " |      >>> from fileinput import input\n",
            " |      >>> from glob import glob\n",
            " |      >>> ''.join(sorted(input(glob(tempFile.name + \"/part-0000*\"))))\n",
            " |      '0\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n'\n",
            " |      \n",
            " |      Empty lines are tolerated when saving to text files.\n",
            " |      \n",
            " |      >>> tempFile2 = NamedTemporaryFile(delete=True)\n",
            " |      >>> tempFile2.close()\n",
            " |      >>> sc.parallelize(['', 'foo', '', 'bar', '']).saveAsTextFile(tempFile2.name)\n",
            " |      >>> ''.join(sorted(input(glob(tempFile2.name + \"/part-0000*\"))))\n",
            " |      '\\n\\n\\nbar\\nfoo\\n'\n",
            " |      \n",
            " |      Using compressionCodecClass\n",
            " |      \n",
            " |      >>> tempFile3 = NamedTemporaryFile(delete=True)\n",
            " |      >>> tempFile3.close()\n",
            " |      >>> codec = \"org.apache.hadoop.io.compress.GzipCodec\"\n",
            " |      >>> sc.parallelize(['foo', 'bar']).saveAsTextFile(tempFile3.name, codec)\n",
            " |      >>> from fileinput import input, hook_compressed\n",
            " |      >>> result = sorted(input(glob(tempFile3.name + \"/part*.gz\"), openhook=hook_compressed))\n",
            " |      >>> b''.join(result).decode('utf-8')\n",
            " |      'bar\\nfoo\\n'\n",
            " |  \n",
            " |  setName(self, name)\n",
            " |      Assign a name to this RDD.\n",
            " |      \n",
            " |      >>> rdd1 = sc.parallelize([1, 2])\n",
            " |      >>> rdd1.setName('RDD1').name()\n",
            " |      'RDD1'\n",
            " |  \n",
            " |  sortBy(self, keyfunc, ascending=True, numPartitions=None)\n",
            " |      Sorts this RDD by the given keyfunc\n",
            " |      \n",
            " |      >>> tmp = [('a', 1), ('b', 2), ('1', 3), ('d', 4), ('2', 5)]\n",
            " |      >>> sc.parallelize(tmp).sortBy(lambda x: x[0]).collect()\n",
            " |      [('1', 3), ('2', 5), ('a', 1), ('b', 2), ('d', 4)]\n",
            " |      >>> sc.parallelize(tmp).sortBy(lambda x: x[1]).collect()\n",
            " |      [('a', 1), ('b', 2), ('1', 3), ('d', 4), ('2', 5)]\n",
            " |  \n",
            " |  sortByKey(self, ascending=True, numPartitions=None, keyfunc=<function RDD.<lambda> at 0x7ff5159be510>)\n",
            " |      Sorts this RDD, which is assumed to consist of (key, value) pairs.\n",
            " |      \n",
            " |      >>> tmp = [('a', 1), ('b', 2), ('1', 3), ('d', 4), ('2', 5)]\n",
            " |      >>> sc.parallelize(tmp).sortByKey().first()\n",
            " |      ('1', 3)\n",
            " |      >>> sc.parallelize(tmp).sortByKey(True, 1).collect()\n",
            " |      [('1', 3), ('2', 5), ('a', 1), ('b', 2), ('d', 4)]\n",
            " |      >>> sc.parallelize(tmp).sortByKey(True, 2).collect()\n",
            " |      [('1', 3), ('2', 5), ('a', 1), ('b', 2), ('d', 4)]\n",
            " |      >>> tmp2 = [('Mary', 1), ('had', 2), ('a', 3), ('little', 4), ('lamb', 5)]\n",
            " |      >>> tmp2.extend([('whose', 6), ('fleece', 7), ('was', 8), ('white', 9)])\n",
            " |      >>> sc.parallelize(tmp2).sortByKey(True, 3, keyfunc=lambda k: k.lower()).collect()\n",
            " |      [('a', 3), ('fleece', 7), ('had', 2), ('lamb', 5),...('white', 9), ('whose', 6)]\n",
            " |  \n",
            " |  stats(self)\n",
            " |      Return a :class:`StatCounter` object that captures the mean, variance\n",
            " |      and count of the RDD's elements in one operation.\n",
            " |  \n",
            " |  stdev(self)\n",
            " |      Compute the standard deviation of this RDD's elements.\n",
            " |      \n",
            " |      >>> sc.parallelize([1, 2, 3]).stdev()\n",
            " |      0.816...\n",
            " |  \n",
            " |  subtract(self, other, numPartitions=None)\n",
            " |      Return each value in `self` that is not contained in `other`.\n",
            " |      \n",
            " |      >>> x = sc.parallelize([(\"a\", 1), (\"b\", 4), (\"b\", 5), (\"a\", 3)])\n",
            " |      >>> y = sc.parallelize([(\"a\", 3), (\"c\", None)])\n",
            " |      >>> sorted(x.subtract(y).collect())\n",
            " |      [('a', 1), ('b', 4), ('b', 5)]\n",
            " |  \n",
            " |  subtractByKey(self, other, numPartitions=None)\n",
            " |      Return each (key, value) pair in `self` that has no pair with matching\n",
            " |      key in `other`.\n",
            " |      \n",
            " |      >>> x = sc.parallelize([(\"a\", 1), (\"b\", 4), (\"b\", 5), (\"a\", 2)])\n",
            " |      >>> y = sc.parallelize([(\"a\", 3), (\"c\", None)])\n",
            " |      >>> sorted(x.subtractByKey(y).collect())\n",
            " |      [('b', 4), ('b', 5)]\n",
            " |  \n",
            " |  sum(self)\n",
            " |      Add up the elements in this RDD.\n",
            " |      \n",
            " |      >>> sc.parallelize([1.0, 2.0, 3.0]).sum()\n",
            " |      6.0\n",
            " |  \n",
            " |  sumApprox(self, timeout, confidence=0.95)\n",
            " |      Approximate operation to return the sum within a timeout\n",
            " |      or meet the confidence.\n",
            " |      \n",
            " |      >>> rdd = sc.parallelize(range(1000), 10)\n",
            " |      >>> r = sum(range(1000))\n",
            " |      >>> abs(rdd.sumApprox(1000) - r) / r < 0.05\n",
            " |      True\n",
            " |  \n",
            " |  take(self, num)\n",
            " |      Take the first num elements of the RDD.\n",
            " |      \n",
            " |      It works by first scanning one partition, and use the results from\n",
            " |      that partition to estimate the number of additional partitions needed\n",
            " |      to satisfy the limit.\n",
            " |      \n",
            " |      Translated from the Scala implementation in RDD#take().\n",
            " |      \n",
            " |      .. note:: this method should only be used if the resulting array is expected\n",
            " |          to be small, as all the data is loaded into the driver's memory.\n",
            " |      \n",
            " |      >>> sc.parallelize([2, 3, 4, 5, 6]).cache().take(2)\n",
            " |      [2, 3]\n",
            " |      >>> sc.parallelize([2, 3, 4, 5, 6]).take(10)\n",
            " |      [2, 3, 4, 5, 6]\n",
            " |      >>> sc.parallelize(range(100), 100).filter(lambda x: x > 90).take(3)\n",
            " |      [91, 92, 93]\n",
            " |  \n",
            " |  takeOrdered(self, num, key=None)\n",
            " |      Get the N elements from an RDD ordered in ascending order or as\n",
            " |      specified by the optional key function.\n",
            " |      \n",
            " |      .. note:: this method should only be used if the resulting array is expected\n",
            " |          to be small, as all the data is loaded into the driver's memory.\n",
            " |      \n",
            " |      >>> sc.parallelize([10, 1, 2, 9, 3, 4, 5, 6, 7]).takeOrdered(6)\n",
            " |      [1, 2, 3, 4, 5, 6]\n",
            " |      >>> sc.parallelize([10, 1, 2, 9, 3, 4, 5, 6, 7], 2).takeOrdered(6, key=lambda x: -x)\n",
            " |      [10, 9, 7, 6, 5, 4]\n",
            " |  \n",
            " |  takeSample(self, withReplacement, num, seed=None)\n",
            " |      Return a fixed-size sampled subset of this RDD.\n",
            " |      \n",
            " |      .. note:: This method should only be used if the resulting array is expected\n",
            " |          to be small, as all the data is loaded into the driver's memory.\n",
            " |      \n",
            " |      >>> rdd = sc.parallelize(range(0, 10))\n",
            " |      >>> len(rdd.takeSample(True, 20, 1))\n",
            " |      20\n",
            " |      >>> len(rdd.takeSample(False, 5, 2))\n",
            " |      5\n",
            " |      >>> len(rdd.takeSample(False, 15, 3))\n",
            " |      10\n",
            " |  \n",
            " |  toDF(self, schema=None, sampleRatio=None)\n",
            " |      Converts current :class:`RDD` into a :class:`DataFrame`\n",
            " |      \n",
            " |      This is a shorthand for ``spark.createDataFrame(rdd, schema, sampleRatio)``\n",
            " |      \n",
            " |      :param schema: a :class:`pyspark.sql.types.StructType` or list of names of columns\n",
            " |      :param samplingRatio: the sample ratio of rows used for inferring\n",
            " |      :return: a DataFrame\n",
            " |      \n",
            " |      >>> rdd.toDF().collect()\n",
            " |      [Row(name=u'Alice', age=1)]\n",
            " |  \n",
            " |  toDebugString(self)\n",
            " |      A description of this RDD and its recursive dependencies for debugging.\n",
            " |  \n",
            " |  toLocalIterator(self, prefetchPartitions=False)\n",
            " |      Return an iterator that contains all of the elements in this RDD.\n",
            " |      The iterator will consume as much memory as the largest partition in this RDD.\n",
            " |      With prefetch it may consume up to the memory of the 2 largest partitions.\n",
            " |      \n",
            " |      :param prefetchPartitions: If Spark should pre-fetch the next partition\n",
            " |                                 before it is needed.\n",
            " |      \n",
            " |      >>> rdd = sc.parallelize(range(10))\n",
            " |      >>> [x for x in rdd.toLocalIterator()]\n",
            " |      [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            " |  \n",
            " |  top(self, num, key=None)\n",
            " |      Get the top N elements from an RDD.\n",
            " |      \n",
            " |      .. note:: This method should only be used if the resulting array is expected\n",
            " |          to be small, as all the data is loaded into the driver's memory.\n",
            " |      \n",
            " |      .. note:: It returns the list sorted in descending order.\n",
            " |      \n",
            " |      >>> sc.parallelize([10, 4, 2, 12, 3]).top(1)\n",
            " |      [12]\n",
            " |      >>> sc.parallelize([2, 3, 4, 5, 6], 2).top(2)\n",
            " |      [6, 5]\n",
            " |      >>> sc.parallelize([10, 4, 2, 12, 3]).top(3, key=str)\n",
            " |      [4, 3, 2]\n",
            " |  \n",
            " |  treeAggregate(self, zeroValue, seqOp, combOp, depth=2)\n",
            " |      Aggregates the elements of this RDD in a multi-level tree\n",
            " |      pattern.\n",
            " |      \n",
            " |      :param depth: suggested depth of the tree (default: 2)\n",
            " |      \n",
            " |      >>> add = lambda x, y: x + y\n",
            " |      >>> rdd = sc.parallelize([-5, -4, -3, -2, -1, 1, 2, 3, 4], 10)\n",
            " |      >>> rdd.treeAggregate(0, add, add)\n",
            " |      -5\n",
            " |      >>> rdd.treeAggregate(0, add, add, 1)\n",
            " |      -5\n",
            " |      >>> rdd.treeAggregate(0, add, add, 2)\n",
            " |      -5\n",
            " |      >>> rdd.treeAggregate(0, add, add, 5)\n",
            " |      -5\n",
            " |      >>> rdd.treeAggregate(0, add, add, 10)\n",
            " |      -5\n",
            " |  \n",
            " |  treeReduce(self, f, depth=2)\n",
            " |      Reduces the elements of this RDD in a multi-level tree pattern.\n",
            " |      \n",
            " |      :param depth: suggested depth of the tree (default: 2)\n",
            " |      \n",
            " |      >>> add = lambda x, y: x + y\n",
            " |      >>> rdd = sc.parallelize([-5, -4, -3, -2, -1, 1, 2, 3, 4], 10)\n",
            " |      >>> rdd.treeReduce(add)\n",
            " |      -5\n",
            " |      >>> rdd.treeReduce(add, 1)\n",
            " |      -5\n",
            " |      >>> rdd.treeReduce(add, 2)\n",
            " |      -5\n",
            " |      >>> rdd.treeReduce(add, 5)\n",
            " |      -5\n",
            " |      >>> rdd.treeReduce(add, 10)\n",
            " |      -5\n",
            " |  \n",
            " |  union(self, other)\n",
            " |      Return the union of this RDD and another one.\n",
            " |      \n",
            " |      >>> rdd = sc.parallelize([1, 1, 2, 3])\n",
            " |      >>> rdd.union(rdd).collect()\n",
            " |      [1, 1, 2, 3, 1, 1, 2, 3]\n",
            " |  \n",
            " |  unpersist(self, blocking=False)\n",
            " |      Mark the RDD as non-persistent, and remove all blocks for it from\n",
            " |      memory and disk.\n",
            " |      \n",
            " |      .. versionchanged:: 3.0.0\n",
            " |         Added optional argument `blocking` to specify whether to block until all\n",
            " |         blocks are deleted.\n",
            " |  \n",
            " |  values(self)\n",
            " |      Return an RDD with the values of each tuple.\n",
            " |      \n",
            " |      >>> m = sc.parallelize([(1, 2), (3, 4)]).values()\n",
            " |      >>> m.collect()\n",
            " |      [2, 4]\n",
            " |  \n",
            " |  variance(self)\n",
            " |      Compute the variance of this RDD's elements.\n",
            " |      \n",
            " |      >>> sc.parallelize([1, 2, 3]).variance()\n",
            " |      0.666...\n",
            " |  \n",
            " |  zip(self, other)\n",
            " |      Zips this RDD with another one, returning key-value pairs with the\n",
            " |      first element in each RDD second element in each RDD, etc. Assumes\n",
            " |      that the two RDDs have the same number of partitions and the same\n",
            " |      number of elements in each partition (e.g. one was made through\n",
            " |      a map on the other).\n",
            " |      \n",
            " |      >>> x = sc.parallelize(range(0,5))\n",
            " |      >>> y = sc.parallelize(range(1000, 1005))\n",
            " |      >>> x.zip(y).collect()\n",
            " |      [(0, 1000), (1, 1001), (2, 1002), (3, 1003), (4, 1004)]\n",
            " |  \n",
            " |  zipWithIndex(self)\n",
            " |      Zips this RDD with its element indices.\n",
            " |      \n",
            " |      The ordering is first based on the partition index and then the\n",
            " |      ordering of items within each partition. So the first item in\n",
            " |      the first partition gets index 0, and the last item in the last\n",
            " |      partition receives the largest index.\n",
            " |      \n",
            " |      This method needs to trigger a spark job when this RDD contains\n",
            " |      more than one partitions.\n",
            " |      \n",
            " |      >>> sc.parallelize([\"a\", \"b\", \"c\", \"d\"], 3).zipWithIndex().collect()\n",
            " |      [('a', 0), ('b', 1), ('c', 2), ('d', 3)]\n",
            " |  \n",
            " |  zipWithUniqueId(self)\n",
            " |      Zips this RDD with generated unique Long ids.\n",
            " |      \n",
            " |      Items in the kth partition will get ids k, n+k, 2*n+k, ..., where\n",
            " |      n is the number of partitions. So there may exist gaps, but this\n",
            " |      method won't trigger a spark job, which is different from\n",
            " |      :meth:`zipWithIndex`.\n",
            " |      \n",
            " |      >>> sc.parallelize([\"a\", \"b\", \"c\", \"d\", \"e\"], 3).zipWithUniqueId().collect()\n",
            " |      [('a', 0), ('b', 1), ('c', 4), ('d', 2), ('e', 5)]\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from RDD:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            " |  \n",
            " |  context\n",
            " |      The :class:`SparkContext` that this RDD was created on.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vE0HNwGKMgE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "587c74ea-339f-4cb9-cff4-9ff333f7adb0"
      },
      "source": [
        "integersListRDD.take(5) #Llamamos a una ACCIÓN de Spark (take) que lo que hace es obtener los\n",
        "#primeros 5 registros del RDD. En nuestro caso los números del 1 al 5. "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTkCa9z4KSDX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "b81c72aa-b466-404e-df75-8ed360e2441b"
      },
      "source": [
        "integersListRDD.count() #Ahora ejecutamos otra ACCIÓN (count) que te devuelve la cantidad de registros del RDD.\n",
        "#Como recordamos, integersListRDD lo creamos a partir de las variables en Python."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxRHG4v4R4Rz",
        "colab_type": "text"
      },
      "source": [
        "### Forma 2 - Leyendo archivo con textFile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRIlDQRr4EkJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#De esta manera vamos a leer el archivo 's.txt' con la función 'textFile':\n",
        "rdd = spark.sparkContext.textFile('/content/drive/My Drive/Colab Notebooks/UBA/5-SPARK/Notebook/Txt Shekspeare utilizado/s.txt') #Acá ponemos al archivo 's.txt' que descargamos y pusimos en esa ruta previamente."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPzWiShdsa8T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "e0d0dbcc-9cf2-4807-97e4-70dc3e374bb6"
      },
      "source": [
        "#Este textFile nos devuelve directamente un RDD. \n",
        "rdd #Chequeamos que es una variable 'MapPartitionsRDD'."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "/content/drive/My Drive/Colab Notebooks/UBA/5-SPARK/Notebook/Txt Shekspeare utilizado/s.txt MapPartitionsRDD[5] at textFile at NativeMethodAccessorImpl.java:0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxiacj7U9-Fh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "3d9bc81c-7ce5-4f28-c5e9-693f415d2f02"
      },
      "source": [
        "rdd.count()  #Vemos la cantidad de registros que tiene. "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "124614"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7ot8-hDKZqR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "9ccde772-0c89-457a-b37e-0215a560865c"
      },
      "source": [
        "rdd.take(5) #Vemos los primeros 5 registros: osea las 1ras 5 lineas del txt."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1609', '', 'THE SONNETS', '', 'by William Shakespeare']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQuEiCSwTFcL",
        "colab_type": "text"
      },
      "source": [
        "### Forma 3 - Leyendo datos con el sqlContext"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjqckKbCSN6m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Le pasamos el sc (el sparkContext).\n",
        "sqlContext = SQLContext(sc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBkiBRPxUbLe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Cargamos la información de nuestro s.txt a un DataFrame (nivel de abstracción \"superior\" al RDD: teniendo así nombre de columnas y demás datos):\n",
        "dataframe = sqlContext.read.text('/content/drive/My Drive/Colab Notebooks/UBA/5-SPARK/Notebook/Txt Shekspeare utilizado/s.txt')\n",
        "\n",
        "#Como vimos en la parte teórica, este dataframe es una API de mayor nivel que el RDD, y nos permite ejecutar trabajos de Map-Reduce con\n",
        "#funciones de más alto nivel que el API de RDD."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cKE58VzTabI",
        "colab_type": "text"
      },
      "source": [
        "Arriba pusimos 'read.text' pero tambien hay otras opciones para leer archivos csv, json, archivos con conexiones de BDs JDBC, etc. (para saber que esto tambien se puede)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WogrwH_4Uo97",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "6dba6fe9-b74b-4f02-a057-b768eff22b1e"
      },
      "source": [
        "dataframe"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[value: string]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWc_JpLHUqqz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Y lo que podemos hacer para pasar de DF a RDD es esto:\n",
        "rddCsv = dataframe.rdd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqN2PigYUv2P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "3338e1be-1a67-4bb2-f745-072c1477ed20"
      },
      "source": [
        "rddCsv  #Ahora acá tenemos un RDD que podemos usarlo para procesarlo con acciones y transformaciones."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MapPartitionsRDD[14] at javaToPython at NativeMethodAccessorImpl.java:0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6u4liP2TUx3P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "78a8a3d0-3524-4c0b-c45c-961a11246cd3"
      },
      "source": [
        "rddCsv.take(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(value='1609'),\n",
              " Row(value=''),\n",
              " Row(value='THE SONNETS'),\n",
              " Row(value=''),\n",
              " Row(value='by William Shakespeare')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQ2zW38tNPao",
        "colab_type": "text"
      },
      "source": [
        "# 2-Acciones.\n",
        "\n",
        "Vamos a ver algunas acciones que tiene disponible el API RDD de Spark."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YK9_c-ZANS6q",
        "colab_type": "text"
      },
      "source": [
        "## Count\n",
        "\n",
        "Para obtener la cantidad de registros del RDD."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vL9EXNnGNYPg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "9e2c50ba-99cb-44e3-c01b-abfc4e7847af"
      },
      "source": [
        "integersListRDD.count()  #integersListRDD era la lista de enteros del 1 al 1000."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uui6n-EBjhG",
        "colab_type": "text"
      },
      "source": [
        "### Take\n",
        "\n",
        "Obtiene los primeros n registros del RDD."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-TEqf-RNbqG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "aef0c72d-f85b-4886-8e50-02b59541d215"
      },
      "source": [
        "integersListRDD.take(5)   #Queremos obtener en este caso los 1ros 5 registros del RDD."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3KYoynwBnBf",
        "colab_type": "text"
      },
      "source": [
        "## Collect"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tBbHaOFDk1Q",
        "colab_type": "text"
      },
      "source": [
        "Obtiene TODOS los registros del RDD. Esto es un potencial problema, ya que si los datos no son acotados (si son demasiados) entonces se va a sobrecargar el driver cuando ejecutamos Collect. SOLO se debe ejecutar si de antemano conocemos que la cantidad de datos es acotada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVwrmdsQNezf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b83f0353-6c74-475e-ff52-eff74c099621"
      },
      "source": [
        "integersListRDD.collect() #CUIDADO! \n",
        "                          #como sabemos que integersListRDD tiene solo 1000 registros lo utilizamos, no hay problema."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 18,\n",
              " 19,\n",
              " 20,\n",
              " 21,\n",
              " 22,\n",
              " 23,\n",
              " 24,\n",
              " 25,\n",
              " 26,\n",
              " 27,\n",
              " 28,\n",
              " 29,\n",
              " 30,\n",
              " 31,\n",
              " 32,\n",
              " 33,\n",
              " 34,\n",
              " 35,\n",
              " 36,\n",
              " 37,\n",
              " 38,\n",
              " 39,\n",
              " 40,\n",
              " 41,\n",
              " 42,\n",
              " 43,\n",
              " 44,\n",
              " 45,\n",
              " 46,\n",
              " 47,\n",
              " 48,\n",
              " 49,\n",
              " 50,\n",
              " 51,\n",
              " 52,\n",
              " 53,\n",
              " 54,\n",
              " 55,\n",
              " 56,\n",
              " 57,\n",
              " 58,\n",
              " 59,\n",
              " 60,\n",
              " 61,\n",
              " 62,\n",
              " 63,\n",
              " 64,\n",
              " 65,\n",
              " 66,\n",
              " 67,\n",
              " 68,\n",
              " 69,\n",
              " 70,\n",
              " 71,\n",
              " 72,\n",
              " 73,\n",
              " 74,\n",
              " 75,\n",
              " 76,\n",
              " 77,\n",
              " 78,\n",
              " 79,\n",
              " 80,\n",
              " 81,\n",
              " 82,\n",
              " 83,\n",
              " 84,\n",
              " 85,\n",
              " 86,\n",
              " 87,\n",
              " 88,\n",
              " 89,\n",
              " 90,\n",
              " 91,\n",
              " 92,\n",
              " 93,\n",
              " 94,\n",
              " 95,\n",
              " 96,\n",
              " 97,\n",
              " 98,\n",
              " 99,\n",
              " 100,\n",
              " 101,\n",
              " 102,\n",
              " 103,\n",
              " 104,\n",
              " 105,\n",
              " 106,\n",
              " 107,\n",
              " 108,\n",
              " 109,\n",
              " 110,\n",
              " 111,\n",
              " 112,\n",
              " 113,\n",
              " 114,\n",
              " 115,\n",
              " 116,\n",
              " 117,\n",
              " 118,\n",
              " 119,\n",
              " 120,\n",
              " 121,\n",
              " 122,\n",
              " 123,\n",
              " 124,\n",
              " 125,\n",
              " 126,\n",
              " 127,\n",
              " 128,\n",
              " 129,\n",
              " 130,\n",
              " 131,\n",
              " 132,\n",
              " 133,\n",
              " 134,\n",
              " 135,\n",
              " 136,\n",
              " 137,\n",
              " 138,\n",
              " 139,\n",
              " 140,\n",
              " 141,\n",
              " 142,\n",
              " 143,\n",
              " 144,\n",
              " 145,\n",
              " 146,\n",
              " 147,\n",
              " 148,\n",
              " 149,\n",
              " 150,\n",
              " 151,\n",
              " 152,\n",
              " 153,\n",
              " 154,\n",
              " 155,\n",
              " 156,\n",
              " 157,\n",
              " 158,\n",
              " 159,\n",
              " 160,\n",
              " 161,\n",
              " 162,\n",
              " 163,\n",
              " 164,\n",
              " 165,\n",
              " 166,\n",
              " 167,\n",
              " 168,\n",
              " 169,\n",
              " 170,\n",
              " 171,\n",
              " 172,\n",
              " 173,\n",
              " 174,\n",
              " 175,\n",
              " 176,\n",
              " 177,\n",
              " 178,\n",
              " 179,\n",
              " 180,\n",
              " 181,\n",
              " 182,\n",
              " 183,\n",
              " 184,\n",
              " 185,\n",
              " 186,\n",
              " 187,\n",
              " 188,\n",
              " 189,\n",
              " 190,\n",
              " 191,\n",
              " 192,\n",
              " 193,\n",
              " 194,\n",
              " 195,\n",
              " 196,\n",
              " 197,\n",
              " 198,\n",
              " 199,\n",
              " 200,\n",
              " 201,\n",
              " 202,\n",
              " 203,\n",
              " 204,\n",
              " 205,\n",
              " 206,\n",
              " 207,\n",
              " 208,\n",
              " 209,\n",
              " 210,\n",
              " 211,\n",
              " 212,\n",
              " 213,\n",
              " 214,\n",
              " 215,\n",
              " 216,\n",
              " 217,\n",
              " 218,\n",
              " 219,\n",
              " 220,\n",
              " 221,\n",
              " 222,\n",
              " 223,\n",
              " 224,\n",
              " 225,\n",
              " 226,\n",
              " 227,\n",
              " 228,\n",
              " 229,\n",
              " 230,\n",
              " 231,\n",
              " 232,\n",
              " 233,\n",
              " 234,\n",
              " 235,\n",
              " 236,\n",
              " 237,\n",
              " 238,\n",
              " 239,\n",
              " 240,\n",
              " 241,\n",
              " 242,\n",
              " 243,\n",
              " 244,\n",
              " 245,\n",
              " 246,\n",
              " 247,\n",
              " 248,\n",
              " 249,\n",
              " 250,\n",
              " 251,\n",
              " 252,\n",
              " 253,\n",
              " 254,\n",
              " 255,\n",
              " 256,\n",
              " 257,\n",
              " 258,\n",
              " 259,\n",
              " 260,\n",
              " 261,\n",
              " 262,\n",
              " 263,\n",
              " 264,\n",
              " 265,\n",
              " 266,\n",
              " 267,\n",
              " 268,\n",
              " 269,\n",
              " 270,\n",
              " 271,\n",
              " 272,\n",
              " 273,\n",
              " 274,\n",
              " 275,\n",
              " 276,\n",
              " 277,\n",
              " 278,\n",
              " 279,\n",
              " 280,\n",
              " 281,\n",
              " 282,\n",
              " 283,\n",
              " 284,\n",
              " 285,\n",
              " 286,\n",
              " 287,\n",
              " 288,\n",
              " 289,\n",
              " 290,\n",
              " 291,\n",
              " 292,\n",
              " 293,\n",
              " 294,\n",
              " 295,\n",
              " 296,\n",
              " 297,\n",
              " 298,\n",
              " 299,\n",
              " 300,\n",
              " 301,\n",
              " 302,\n",
              " 303,\n",
              " 304,\n",
              " 305,\n",
              " 306,\n",
              " 307,\n",
              " 308,\n",
              " 309,\n",
              " 310,\n",
              " 311,\n",
              " 312,\n",
              " 313,\n",
              " 314,\n",
              " 315,\n",
              " 316,\n",
              " 317,\n",
              " 318,\n",
              " 319,\n",
              " 320,\n",
              " 321,\n",
              " 322,\n",
              " 323,\n",
              " 324,\n",
              " 325,\n",
              " 326,\n",
              " 327,\n",
              " 328,\n",
              " 329,\n",
              " 330,\n",
              " 331,\n",
              " 332,\n",
              " 333,\n",
              " 334,\n",
              " 335,\n",
              " 336,\n",
              " 337,\n",
              " 338,\n",
              " 339,\n",
              " 340,\n",
              " 341,\n",
              " 342,\n",
              " 343,\n",
              " 344,\n",
              " 345,\n",
              " 346,\n",
              " 347,\n",
              " 348,\n",
              " 349,\n",
              " 350,\n",
              " 351,\n",
              " 352,\n",
              " 353,\n",
              " 354,\n",
              " 355,\n",
              " 356,\n",
              " 357,\n",
              " 358,\n",
              " 359,\n",
              " 360,\n",
              " 361,\n",
              " 362,\n",
              " 363,\n",
              " 364,\n",
              " 365,\n",
              " 366,\n",
              " 367,\n",
              " 368,\n",
              " 369,\n",
              " 370,\n",
              " 371,\n",
              " 372,\n",
              " 373,\n",
              " 374,\n",
              " 375,\n",
              " 376,\n",
              " 377,\n",
              " 378,\n",
              " 379,\n",
              " 380,\n",
              " 381,\n",
              " 382,\n",
              " 383,\n",
              " 384,\n",
              " 385,\n",
              " 386,\n",
              " 387,\n",
              " 388,\n",
              " 389,\n",
              " 390,\n",
              " 391,\n",
              " 392,\n",
              " 393,\n",
              " 394,\n",
              " 395,\n",
              " 396,\n",
              " 397,\n",
              " 398,\n",
              " 399,\n",
              " 400,\n",
              " 401,\n",
              " 402,\n",
              " 403,\n",
              " 404,\n",
              " 405,\n",
              " 406,\n",
              " 407,\n",
              " 408,\n",
              " 409,\n",
              " 410,\n",
              " 411,\n",
              " 412,\n",
              " 413,\n",
              " 414,\n",
              " 415,\n",
              " 416,\n",
              " 417,\n",
              " 418,\n",
              " 419,\n",
              " 420,\n",
              " 421,\n",
              " 422,\n",
              " 423,\n",
              " 424,\n",
              " 425,\n",
              " 426,\n",
              " 427,\n",
              " 428,\n",
              " 429,\n",
              " 430,\n",
              " 431,\n",
              " 432,\n",
              " 433,\n",
              " 434,\n",
              " 435,\n",
              " 436,\n",
              " 437,\n",
              " 438,\n",
              " 439,\n",
              " 440,\n",
              " 441,\n",
              " 442,\n",
              " 443,\n",
              " 444,\n",
              " 445,\n",
              " 446,\n",
              " 447,\n",
              " 448,\n",
              " 449,\n",
              " 450,\n",
              " 451,\n",
              " 452,\n",
              " 453,\n",
              " 454,\n",
              " 455,\n",
              " 456,\n",
              " 457,\n",
              " 458,\n",
              " 459,\n",
              " 460,\n",
              " 461,\n",
              " 462,\n",
              " 463,\n",
              " 464,\n",
              " 465,\n",
              " 466,\n",
              " 467,\n",
              " 468,\n",
              " 469,\n",
              " 470,\n",
              " 471,\n",
              " 472,\n",
              " 473,\n",
              " 474,\n",
              " 475,\n",
              " 476,\n",
              " 477,\n",
              " 478,\n",
              " 479,\n",
              " 480,\n",
              " 481,\n",
              " 482,\n",
              " 483,\n",
              " 484,\n",
              " 485,\n",
              " 486,\n",
              " 487,\n",
              " 488,\n",
              " 489,\n",
              " 490,\n",
              " 491,\n",
              " 492,\n",
              " 493,\n",
              " 494,\n",
              " 495,\n",
              " 496,\n",
              " 497,\n",
              " 498,\n",
              " 499,\n",
              " 500,\n",
              " 501,\n",
              " 502,\n",
              " 503,\n",
              " 504,\n",
              " 505,\n",
              " 506,\n",
              " 507,\n",
              " 508,\n",
              " 509,\n",
              " 510,\n",
              " 511,\n",
              " 512,\n",
              " 513,\n",
              " 514,\n",
              " 515,\n",
              " 516,\n",
              " 517,\n",
              " 518,\n",
              " 519,\n",
              " 520,\n",
              " 521,\n",
              " 522,\n",
              " 523,\n",
              " 524,\n",
              " 525,\n",
              " 526,\n",
              " 527,\n",
              " 528,\n",
              " 529,\n",
              " 530,\n",
              " 531,\n",
              " 532,\n",
              " 533,\n",
              " 534,\n",
              " 535,\n",
              " 536,\n",
              " 537,\n",
              " 538,\n",
              " 539,\n",
              " 540,\n",
              " 541,\n",
              " 542,\n",
              " 543,\n",
              " 544,\n",
              " 545,\n",
              " 546,\n",
              " 547,\n",
              " 548,\n",
              " 549,\n",
              " 550,\n",
              " 551,\n",
              " 552,\n",
              " 553,\n",
              " 554,\n",
              " 555,\n",
              " 556,\n",
              " 557,\n",
              " 558,\n",
              " 559,\n",
              " 560,\n",
              " 561,\n",
              " 562,\n",
              " 563,\n",
              " 564,\n",
              " 565,\n",
              " 566,\n",
              " 567,\n",
              " 568,\n",
              " 569,\n",
              " 570,\n",
              " 571,\n",
              " 572,\n",
              " 573,\n",
              " 574,\n",
              " 575,\n",
              " 576,\n",
              " 577,\n",
              " 578,\n",
              " 579,\n",
              " 580,\n",
              " 581,\n",
              " 582,\n",
              " 583,\n",
              " 584,\n",
              " 585,\n",
              " 586,\n",
              " 587,\n",
              " 588,\n",
              " 589,\n",
              " 590,\n",
              " 591,\n",
              " 592,\n",
              " 593,\n",
              " 594,\n",
              " 595,\n",
              " 596,\n",
              " 597,\n",
              " 598,\n",
              " 599,\n",
              " 600,\n",
              " 601,\n",
              " 602,\n",
              " 603,\n",
              " 604,\n",
              " 605,\n",
              " 606,\n",
              " 607,\n",
              " 608,\n",
              " 609,\n",
              " 610,\n",
              " 611,\n",
              " 612,\n",
              " 613,\n",
              " 614,\n",
              " 615,\n",
              " 616,\n",
              " 617,\n",
              " 618,\n",
              " 619,\n",
              " 620,\n",
              " 621,\n",
              " 622,\n",
              " 623,\n",
              " 624,\n",
              " 625,\n",
              " 626,\n",
              " 627,\n",
              " 628,\n",
              " 629,\n",
              " 630,\n",
              " 631,\n",
              " 632,\n",
              " 633,\n",
              " 634,\n",
              " 635,\n",
              " 636,\n",
              " 637,\n",
              " 638,\n",
              " 639,\n",
              " 640,\n",
              " 641,\n",
              " 642,\n",
              " 643,\n",
              " 644,\n",
              " 645,\n",
              " 646,\n",
              " 647,\n",
              " 648,\n",
              " 649,\n",
              " 650,\n",
              " 651,\n",
              " 652,\n",
              " 653,\n",
              " 654,\n",
              " 655,\n",
              " 656,\n",
              " 657,\n",
              " 658,\n",
              " 659,\n",
              " 660,\n",
              " 661,\n",
              " 662,\n",
              " 663,\n",
              " 664,\n",
              " 665,\n",
              " 666,\n",
              " 667,\n",
              " 668,\n",
              " 669,\n",
              " 670,\n",
              " 671,\n",
              " 672,\n",
              " 673,\n",
              " 674,\n",
              " 675,\n",
              " 676,\n",
              " 677,\n",
              " 678,\n",
              " 679,\n",
              " 680,\n",
              " 681,\n",
              " 682,\n",
              " 683,\n",
              " 684,\n",
              " 685,\n",
              " 686,\n",
              " 687,\n",
              " 688,\n",
              " 689,\n",
              " 690,\n",
              " 691,\n",
              " 692,\n",
              " 693,\n",
              " 694,\n",
              " 695,\n",
              " 696,\n",
              " 697,\n",
              " 698,\n",
              " 699,\n",
              " 700,\n",
              " 701,\n",
              " 702,\n",
              " 703,\n",
              " 704,\n",
              " 705,\n",
              " 706,\n",
              " 707,\n",
              " 708,\n",
              " 709,\n",
              " 710,\n",
              " 711,\n",
              " 712,\n",
              " 713,\n",
              " 714,\n",
              " 715,\n",
              " 716,\n",
              " 717,\n",
              " 718,\n",
              " 719,\n",
              " 720,\n",
              " 721,\n",
              " 722,\n",
              " 723,\n",
              " 724,\n",
              " 725,\n",
              " 726,\n",
              " 727,\n",
              " 728,\n",
              " 729,\n",
              " 730,\n",
              " 731,\n",
              " 732,\n",
              " 733,\n",
              " 734,\n",
              " 735,\n",
              " 736,\n",
              " 737,\n",
              " 738,\n",
              " 739,\n",
              " 740,\n",
              " 741,\n",
              " 742,\n",
              " 743,\n",
              " 744,\n",
              " 745,\n",
              " 746,\n",
              " 747,\n",
              " 748,\n",
              " 749,\n",
              " 750,\n",
              " 751,\n",
              " 752,\n",
              " 753,\n",
              " 754,\n",
              " 755,\n",
              " 756,\n",
              " 757,\n",
              " 758,\n",
              " 759,\n",
              " 760,\n",
              " 761,\n",
              " 762,\n",
              " 763,\n",
              " 764,\n",
              " 765,\n",
              " 766,\n",
              " 767,\n",
              " 768,\n",
              " 769,\n",
              " 770,\n",
              " 771,\n",
              " 772,\n",
              " 773,\n",
              " 774,\n",
              " 775,\n",
              " 776,\n",
              " 777,\n",
              " 778,\n",
              " 779,\n",
              " 780,\n",
              " 781,\n",
              " 782,\n",
              " 783,\n",
              " 784,\n",
              " 785,\n",
              " 786,\n",
              " 787,\n",
              " 788,\n",
              " 789,\n",
              " 790,\n",
              " 791,\n",
              " 792,\n",
              " 793,\n",
              " 794,\n",
              " 795,\n",
              " 796,\n",
              " 797,\n",
              " 798,\n",
              " 799,\n",
              " 800,\n",
              " 801,\n",
              " 802,\n",
              " 803,\n",
              " 804,\n",
              " 805,\n",
              " 806,\n",
              " 807,\n",
              " 808,\n",
              " 809,\n",
              " 810,\n",
              " 811,\n",
              " 812,\n",
              " 813,\n",
              " 814,\n",
              " 815,\n",
              " 816,\n",
              " 817,\n",
              " 818,\n",
              " 819,\n",
              " 820,\n",
              " 821,\n",
              " 822,\n",
              " 823,\n",
              " 824,\n",
              " 825,\n",
              " 826,\n",
              " 827,\n",
              " 828,\n",
              " 829,\n",
              " 830,\n",
              " 831,\n",
              " 832,\n",
              " 833,\n",
              " 834,\n",
              " 835,\n",
              " 836,\n",
              " 837,\n",
              " 838,\n",
              " 839,\n",
              " 840,\n",
              " 841,\n",
              " 842,\n",
              " 843,\n",
              " 844,\n",
              " 845,\n",
              " 846,\n",
              " 847,\n",
              " 848,\n",
              " 849,\n",
              " 850,\n",
              " 851,\n",
              " 852,\n",
              " 853,\n",
              " 854,\n",
              " 855,\n",
              " 856,\n",
              " 857,\n",
              " 858,\n",
              " 859,\n",
              " 860,\n",
              " 861,\n",
              " 862,\n",
              " 863,\n",
              " 864,\n",
              " 865,\n",
              " 866,\n",
              " 867,\n",
              " 868,\n",
              " 869,\n",
              " 870,\n",
              " 871,\n",
              " 872,\n",
              " 873,\n",
              " 874,\n",
              " 875,\n",
              " 876,\n",
              " 877,\n",
              " 878,\n",
              " 879,\n",
              " 880,\n",
              " 881,\n",
              " 882,\n",
              " 883,\n",
              " 884,\n",
              " 885,\n",
              " 886,\n",
              " 887,\n",
              " 888,\n",
              " 889,\n",
              " 890,\n",
              " 891,\n",
              " 892,\n",
              " 893,\n",
              " 894,\n",
              " 895,\n",
              " 896,\n",
              " 897,\n",
              " 898,\n",
              " 899,\n",
              " 900,\n",
              " 901,\n",
              " 902,\n",
              " 903,\n",
              " 904,\n",
              " 905,\n",
              " 906,\n",
              " 907,\n",
              " 908,\n",
              " 909,\n",
              " 910,\n",
              " 911,\n",
              " 912,\n",
              " 913,\n",
              " 914,\n",
              " 915,\n",
              " 916,\n",
              " 917,\n",
              " 918,\n",
              " 919,\n",
              " 920,\n",
              " 921,\n",
              " 922,\n",
              " 923,\n",
              " 924,\n",
              " 925,\n",
              " 926,\n",
              " 927,\n",
              " 928,\n",
              " 929,\n",
              " 930,\n",
              " 931,\n",
              " 932,\n",
              " 933,\n",
              " 934,\n",
              " 935,\n",
              " 936,\n",
              " 937,\n",
              " 938,\n",
              " 939,\n",
              " 940,\n",
              " 941,\n",
              " 942,\n",
              " 943,\n",
              " 944,\n",
              " 945,\n",
              " 946,\n",
              " 947,\n",
              " 948,\n",
              " 949,\n",
              " 950,\n",
              " 951,\n",
              " 952,\n",
              " 953,\n",
              " 954,\n",
              " 955,\n",
              " 956,\n",
              " 957,\n",
              " 958,\n",
              " 959,\n",
              " 960,\n",
              " 961,\n",
              " 962,\n",
              " 963,\n",
              " 964,\n",
              " 965,\n",
              " 966,\n",
              " 967,\n",
              " 968,\n",
              " 969,\n",
              " 970,\n",
              " 971,\n",
              " 972,\n",
              " 973,\n",
              " 974,\n",
              " 975,\n",
              " 976,\n",
              " 977,\n",
              " 978,\n",
              " 979,\n",
              " 980,\n",
              " 981,\n",
              " 982,\n",
              " 983,\n",
              " 984,\n",
              " 985,\n",
              " 986,\n",
              " 987,\n",
              " 988,\n",
              " 989,\n",
              " 990,\n",
              " 991,\n",
              " 992,\n",
              " 993,\n",
              " 994,\n",
              " 995,\n",
              " 996,\n",
              " 997,\n",
              " 998,\n",
              " 999,\n",
              " 1000]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkau0dZTBq8Z",
        "colab_type": "text"
      },
      "source": [
        "## First\n",
        "\n",
        "Obtiene el primer registro del RDD."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOYGelqqNkCC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "1b8250ec-f919-465e-ac38-27c8d01e8274"
      },
      "source": [
        "integersListRDD.first()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FwrpPTlBuhZ",
        "colab_type": "text"
      },
      "source": [
        "## TakeOrdered\n",
        "\n",
        "Obtiene los primeros n registros en base a un ORDEN indicado (mediante una función de ordenamiento)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DslDO0f8NtI2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "95b48e3c-2600-4a4f-cf64-cec362a3dc3b"
      },
      "source": [
        "integersListRDD.takeOrdered(5, key=lambda x: -x) \n",
        "  #1er parámetro (5): cantidad de registro que queremos obtener.\n",
        "  #2do parámetro: es la key de ordenamiento. En este caso decimos que la key del ordenamiento es = a la función lambda x - x... osea que\n",
        "  #estamos ordenando los números de forma descendente. \n",
        "  #De esta manera obtenemos los números más grandes (si quisieramos los más chicos simplemente pondríamos \"lambda x: x\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1000, 999, 998, 997, 996]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YunCyrJBBxii",
        "colab_type": "text"
      },
      "source": [
        "## TakeSample\n",
        "\n",
        "Obtiene una muestra aleatoria de n registros con o sin reemplazo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R94o47hlN-OG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "1e8c8144-db73-4eb4-ade2-4101ebad477f"
      },
      "source": [
        "integersListRDD.takeSample(False, 5)\n",
        "  #1er parametro: variable booleana que me dice si la muestra es CON (true) o SIN (false) reemplazo (osea si\n",
        "  #un registro puede ser elegido más de 1 vez).\n",
        "  #2do parámetro: cantidad de registro que quermeos obtener.\n",
        "  #3er paráemtros opcional: la semilla, seed. Es para el tema de aleatoriedad. Si queremos obtener los mismos registros ponemos la misma semilla, sino ponemos otra."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[125, 517, 994, 680, 172]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfFmi9hMB0fz",
        "colab_type": "text"
      },
      "source": [
        "## Reduce\n",
        "\n",
        "Obtiene un solo registro, combinando el resultado en base a una función dada (En base a una función Reduce que toma de a 2 valores)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uA5TMBcKEkrM",
        "colab_type": "text"
      },
      "source": [
        "Por ej. para SUMAR todos los nros del RDD utilizamos la acción Reduce y le pasamos un lambda que recibe 2 registros de nombre a y b... y lo que hacemos es sumar a y b. De esta manera lo que hacemos es SUMAR DE A PARES TODOS LOS NÚMEROS. Y como resultado obtenemos la suma de los mil números de nuestro RDD."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1aRuIdcOG8T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "b8ff8ece-063b-471c-9830-4dbf8edf584c"
      },
      "source": [
        "integersListRDD.reduce(lambda a,b: a+b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPldfWT_EnQW",
        "colab_type": "text"
      },
      "source": [
        "Entonces, dependiendo de la función lambda en la función reduce que utilicemos, podemos obtener distinta información del RDD. Si por ejemplo ahora queremos **obtener el número más grande del RDD**... hacemos una función lambda que se quede con el número más grande entre a y b. \n",
        "\n",
        "Utilizar esta función para obtener el MIN o el MAX de un RDD cuando tenemos muchos datos **es mucho más eficiente que hacer un ordenamiento** previo (con takeordered) y luego obtener el mayor o menor de ese ordenamiento: esto último es muy costoso cuando tenemos muchos datos. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoZe4PTeEZU0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "9dd49136-441d-4208-fda7-5d38ca45b272"
      },
      "source": [
        "integersListRDD.reduce(lambda a,b: a if a > b else b) #Se queda con a si (if) es mayor a b y sino (else) se queda con b."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqtSjN_4B2sY",
        "colab_type": "text"
      },
      "source": [
        "## CountByKey\n",
        "\n",
        "Cuenta ocurrencias de registros para cada clave."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIC-fAW-EziF",
        "colab_type": "text"
      },
      "source": [
        "En Spark **para que un registro sea considerado que tenga una clave debe ser una tupla de únicamente dos elementos. El primer elemento es la key y el segundo el valor.** A su vez, cada key y cada valor pueden estar compuestos por tuplas compuestas... entonces quizás la key es otra tupla de 2 elementos y el valor es una tupla de 5 elementos.\n",
        "\n",
        "De esta forma, si tenemos un registro que es una tupla de 2 elementos podemos ejecutar transformaciones y acciones que trabajen con clave. Y si trabajamos con registros que NO tienen 2 elementos entonces NO podemos utilizar las transformaciones o acciones que trabajen con una key; y si necesitamos si o si utilizar una de estas deberíamos mapear primero los datos para que tenga una tupla de 2 elementos. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HioGdGD8FJld",
        "colab_type": "text"
      },
      "source": [
        "Acá por ejemplo contamos cuántos números múltiplo de 2 hay y cuántos no:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMrNtCjlOOvW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "bf9ad982-6af1-46eb-8ed1-5326ff5d50d5"
      },
      "source": [
        "#1ro mapeamos cada uno de los registros (usando la transformación MAP). De esta manera x es\n",
        "#el 1er elemento (clave) y le ponemos un 0 o un 1 indicando si es o no múltiplo de 2 (Si es par o impar).\n",
        "#Y en el 2do elemento (Valor) simplemente le ponemos un 1 SIEMPRE. \n",
        "integersListRDD.map(lambda x: (x % 2, 1)).take(10)  #Tomamos los 1ros 10 elementos."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 1),\n",
              " (0, 1),\n",
              " (1, 1),\n",
              " (0, 1),\n",
              " (1, 1),\n",
              " (0, 1),\n",
              " (1, 1),\n",
              " (0, 1),\n",
              " (1, 1),\n",
              " (0, 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOD3vAgX-93n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "e297ce26-ed62-41ce-cebb-c17ed51ae3b0"
      },
      "source": [
        "#Y ahora si usamos countByKey() para contar cuántos registros hay de cada clave... vemos que hay 500 elementos pares (cuando el módulo es 0, clave 0)\n",
        "#y 500 números impares (clave=1). \n",
        "integersListRDD.map(lambda x: (x % 2, 1)).countByKey()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(int, {0: 500, 1: 500})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wICWjRrq9LGk",
        "colab_type": "text"
      },
      "source": [
        "# 3-Transformaciones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htCboCCE9OxU",
        "colab_type": "text"
      },
      "source": [
        "### Map\n",
        "\n",
        "Transforma cada registro en base a la función dada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Amp0bYmSG-c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "9eedbd1d-0aa1-4d45-e135-2c8a852b05d9"
      },
      "source": [
        "#MAP recibe una función que indica cómo transformar cada uno de los registros del RDD.\n",
        "#En este caso usamos la función de lamba x*2.. osea vamos a multiplicar x 2 cada uno de nuestros registros y luego obtenemos con take los 1ros 5.\n",
        "integersListRDD.map(lambda x: x*2).take(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 4, 6, 8, 10]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hM5gotbf9R-W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "3257f59c-8e1f-49c9-9f74-38c1b607c83e"
      },
      "source": [
        "#La función map NO es necesario que reciba 1 número y devuelva 1 número... acá abajo recibimos 1 número x pero\n",
        "#devolvemos una tupla de 2 elementos (parecido a como hicimos 2 lineas de código arriba, solo que ahora le vamos a colocar el número (x) envés de un simple 1 en la posición del 'valor'. En la posición\n",
        "#de la 'clave' seguirá un 0 si el número es múltiplo de 2 o un 1 si no lo es.\n",
        "integersListRDD.map(lambda x: (x % 2, x)).take(5)  #Y tomamos los 1ros 5 números.\n",
        "\n",
        "#Vemos que 1 es impar, 2 es par, 3 impar, 4 par, 5 impar y asi...\n",
        "#De esta forma transformamos nuestros números en una tupla indicando si el número es par o no.\n",
        "#Como es una tupla de 2 elementos entonces SPARK reconoce al primero (al 0 o al 1) como el elemento 'key' y\n",
        "#al resto de los números (1,2,3,4,5,6...) como los 'value'. De esta manera me permitiría ejecutar en estas tuplas transformaciones o acciones que trabajen con clave."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 1), (0, 2), (1, 3), (0, 4), (1, 5)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGGRoh-d9k4P",
        "colab_type": "text"
      },
      "source": [
        "## Filter\n",
        "\n",
        "Filtra registros en base a la función dada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0l43_s89wpW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "8a680ee6-17d5-4ebd-9cb8-74caaa627425"
      },
      "source": [
        "#Esta función FILTER devuelve un TRUE o FALSE en base a si cumple o no la función. \n",
        "#Si queremos mantener ese registro devuelve TRUE y si queremos que lo descarte devuelve FALSE.\n",
        "#Filtramos / descartamos los regisotrs quedandonos solo con los registros que son PARES.\n",
        "integersListRDD.filter(lambda x: x % 2 == 0).take(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 4, 6, 8, 10]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWEZW0D70HWU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "dfabdbb5-49f5-4dd9-98bb-214e4261aa26"
      },
      "source": [
        "integersListRDD.filter(lambda x: x % 2 == 0).count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0ZHNYdO-ExA",
        "colab_type": "text"
      },
      "source": [
        "## FlatMap\n",
        "\n",
        "Similar a Map, pero cada registro puede generar 0, 1 o más registros (NO hay limitaciones en la cantidad de registros que podemos dar como salida usando FlatMap)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVQdUOkHGQgl",
        "colab_type": "text"
      },
      "source": [
        "De esta manera, con flatMap recibimos una función de transformación. En este caso en lambda x devolvemos 3 registros para cada registro original: Un registro que tiene 'x', otro que es 'x-1', y otro que es 'x+1'.\n",
        "\n",
        "Así, para cada registro original generamos 3 nuevos registros."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09N_gedZ-BSu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "da669a94-7738-4427-fc9b-9dafadd20532"
      },
      "source": [
        "integersFlat = integersListRDD.flatMap(lambda x: [(x), (x-1), (x+1)])\n",
        "integersFlat.count() #De esta manera, como originalmente teníamos 1000 registros, ahora tendremos 3000."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftix955HDhE3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "4d51a27b-c9c6-4f40-90f9-08cb880c6cfc"
      },
      "source": [
        "integersFlat.take(6)  #Así, el 1er registro que era 1... ahora tenemos 1 (Que es el mismo\n",
        "#registro), 0 (registro-1) y 2 (registro+1). Y para el 2do registro que era 2 lo mismo (tenemos 2, 1 y 3):"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 0, 2, 2, 1, 3]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOJAhi5O-haG",
        "colab_type": "text"
      },
      "source": [
        "## ReduceByKey\n",
        "\n",
        "Combina los registros que tengan una misma clave en base a una función de Reduce. Como dijimos, una función de Reduce recibe 2 registros a la vez y los combina con una función. Acá recordemos que la función de Reduce debe ser **conmutativa** y **asociativa** para que el resultado tenga sentido (ya que va trabajando de forma distribuida de a pares). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcWSQNr7Gggz",
        "colab_type": "text"
      },
      "source": [
        "Del RDD salida del flatMap que hicimos anteriormente (en el que teniamos 3000 registros), ahora contamos cuantos registros hay para cada nro:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ak--UX3-zLm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "0dec0a1a-01b9-4a30-fa39-8d8ad3e74b39"
      },
      "source": [
        "#integersFlat son los 3000 enteros que obtuvimos del flatMap anterior.\n",
        "#Del map devolvemos el número x y un 1 --> '(x,1)'. Y luego aplicamos un reduceByKey y le pasamos\n",
        "#la función de Reduce donde hacemos simplemente a+b. Acá hay que tener en cuenta que estos a y b NO son todos\n",
        "#los registros, sino que es únicamente la parte del valor del registro (osea el 2do elemento de la tupla)... osea en este caso\n",
        "#va a estar recibiendo el 1 --> por el '(x,1)' anterior. \n",
        "#Entonces, para todos los registros que tengan la misma clave va a estar recibiendo ese 2do 1 y entonces\n",
        "#va a estar sumando 1+1+1+1+1 y así... (en el 'a+b') en base a todos los registros que hayan para esa clave.\n",
        "integersFlat.map(lambda x: (x, 1)).reduceByKey(lambda a,b: a+b).count()   #Y tambien ejecutamos la acción de count() para contar.\n",
        "\n",
        "#Tenemos 1000 registros que cumplen esto... los 1000 registros originales + el 1 inicial que le restamos y el 1 final que le sumamos \n",
        "#(El 0 y el 1001). Vamos a ver este 0 y 10001 para comprobar abajo..."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1002"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbH-NuM61Dbb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "4a6dd2ad-98a5-4975-c3b0-383bf7516f3d"
      },
      "source": [
        "#Primero vemos que el 0 que dijimos previamente:\n",
        "integersFlat.map(lambda x: (x, 1)).reduceByKey(lambda a,b: a+b).take(10)\n",
        "#Acá vemos que tenemos solo un 0 (el que dijimos), tres 8s, tres 16s, etc. Vamos a tener 3 de toodos los demás números (menos del 1001 que vemos abajo si está al final o no)..."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 1),\n",
              " (8, 3),\n",
              " (16, 3),\n",
              " (24, 3),\n",
              " (32, 3),\n",
              " (40, 3),\n",
              " (48, 3),\n",
              " (56, 3),\n",
              " (64, 3),\n",
              " (72, 3)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwncZCGB1Ind",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "f4303ce6-e905-4dd6-f132-f489f1c1d390"
      },
      "source": [
        "#Y ahora vemos el final para comprobar que está el 1001 que dijimos previamente:\n",
        "#De esta manera usamos un reduce que recibe un lambda a,b y devolvemos solo el mayor. \n",
        "integersFlat.map(lambda x: (x, 1)).reduceByKey(lambda a,b: a+b).reduce(lambda a,b: a if a > b else b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1001, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXS7ZVE4_lDB",
        "colab_type": "text"
      },
      "source": [
        "## GroupByKey\n",
        "\n",
        "Agrupa los registros para cada clave. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myQ_LslrIGU7",
        "colab_type": "text"
      },
      "source": [
        "Es similar a reduceByKey pero con groupByKey se obtiene todos los registros para cada clave. Enves de aplicar una función de Reduce para cada uno de los registros de la misma clave, lo que va a hacer GroupByKey es AGRUPAR los registros para cada clave y nos lo va a devolver en cada uno de los registros... osea ahora vamos a tener en cada registro la clave como 1er elemento y como 2do elemento a cada uno de los valores que tenia esa clave en los registros originales (osea si teniamos 3 registros para la clave 1, luego de realizar el GroupByKey vamos a tener un registro que es clave 1 y como valor cada uno de estos 3 registros... y esto lo va a hacer para cada una de las claves distintas que aparezcan en el RDD). \n",
        "\n",
        "**Esto se utiliza en casos muy particulares, ya que es una operación MUY costosa**. La mayoría de las veces envés de utilizar GroupByKey podemos usar ReduceByKey. GroupByKey se usa únicamente cuando por alguna razón necesitamos hacer algo con los registros ORIGINALES y no alcanza con hacer una función de agregación a los registros. Además de ser costosa nos puede traer problemas... ya que quizás para una sola clave hayan cientos de miles de registros que tengan esa clave... entonces va a pasar que cada registro va a ser de un tamaño muy grande.\n",
        "\n",
        "**Hay que usarlo con cuidado y SOLO si es MUY necesario. Hay que pensar previamente si nuestro problema no se puede resolver con un ReduceByKey. Si se desea realizar una agregación, usar reduceByKey. Usar groupByKey para hacer una agregación esta MAL.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XM84FFQbHxcZ",
        "colab_type": "text"
      },
      "source": [
        "Antes habíamos calculado cuántos eran múltiplos de 2 y cuántos no. Ahora queremos saber CUALES son los nros múltiplos de 2 y cuales no:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXi4mcm0_kFB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fc929949-de41-47e7-d850-538de6227a67"
      },
      "source": [
        "#Y con esto obtenemos:\n",
        "  #un 0 como clave y como valor una lista tooooodos los valores pares, \n",
        "  #o un 1 como clave y como valor una lista con tooooodos los valores impares. \n",
        "integersListRDD.map(lambda x: (x % 2, x)).groupByKey().map(lambda x: (x[0], list(x[1]))).collect()\n",
        "#El 2do map es totalmente innecesario, es solo para que se pueda ver... si no la ejecutamos la parte de los registros agrupados se van a ver como iterables de RDD y no se\n",
        "#va a haber el contenido; entonces transformando cada uno de estos registros en un 'list' podemos ver el contenido."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0,\n",
              "  [2,\n",
              "   4,\n",
              "   6,\n",
              "   8,\n",
              "   10,\n",
              "   12,\n",
              "   14,\n",
              "   16,\n",
              "   18,\n",
              "   20,\n",
              "   22,\n",
              "   24,\n",
              "   26,\n",
              "   28,\n",
              "   30,\n",
              "   32,\n",
              "   34,\n",
              "   36,\n",
              "   38,\n",
              "   40,\n",
              "   42,\n",
              "   44,\n",
              "   46,\n",
              "   48,\n",
              "   50,\n",
              "   52,\n",
              "   54,\n",
              "   56,\n",
              "   58,\n",
              "   60,\n",
              "   62,\n",
              "   64,\n",
              "   66,\n",
              "   68,\n",
              "   70,\n",
              "   72,\n",
              "   74,\n",
              "   76,\n",
              "   78,\n",
              "   80,\n",
              "   82,\n",
              "   84,\n",
              "   86,\n",
              "   88,\n",
              "   90,\n",
              "   92,\n",
              "   94,\n",
              "   96,\n",
              "   98,\n",
              "   100,\n",
              "   102,\n",
              "   104,\n",
              "   106,\n",
              "   108,\n",
              "   110,\n",
              "   112,\n",
              "   114,\n",
              "   116,\n",
              "   118,\n",
              "   120,\n",
              "   122,\n",
              "   124,\n",
              "   126,\n",
              "   128,\n",
              "   130,\n",
              "   132,\n",
              "   134,\n",
              "   136,\n",
              "   138,\n",
              "   140,\n",
              "   142,\n",
              "   144,\n",
              "   146,\n",
              "   148,\n",
              "   150,\n",
              "   152,\n",
              "   154,\n",
              "   156,\n",
              "   158,\n",
              "   160,\n",
              "   162,\n",
              "   164,\n",
              "   166,\n",
              "   168,\n",
              "   170,\n",
              "   172,\n",
              "   174,\n",
              "   176,\n",
              "   178,\n",
              "   180,\n",
              "   182,\n",
              "   184,\n",
              "   186,\n",
              "   188,\n",
              "   190,\n",
              "   192,\n",
              "   194,\n",
              "   196,\n",
              "   198,\n",
              "   200,\n",
              "   202,\n",
              "   204,\n",
              "   206,\n",
              "   208,\n",
              "   210,\n",
              "   212,\n",
              "   214,\n",
              "   216,\n",
              "   218,\n",
              "   220,\n",
              "   222,\n",
              "   224,\n",
              "   226,\n",
              "   228,\n",
              "   230,\n",
              "   232,\n",
              "   234,\n",
              "   236,\n",
              "   238,\n",
              "   240,\n",
              "   242,\n",
              "   244,\n",
              "   246,\n",
              "   248,\n",
              "   250,\n",
              "   252,\n",
              "   254,\n",
              "   256,\n",
              "   258,\n",
              "   260,\n",
              "   262,\n",
              "   264,\n",
              "   266,\n",
              "   268,\n",
              "   270,\n",
              "   272,\n",
              "   274,\n",
              "   276,\n",
              "   278,\n",
              "   280,\n",
              "   282,\n",
              "   284,\n",
              "   286,\n",
              "   288,\n",
              "   290,\n",
              "   292,\n",
              "   294,\n",
              "   296,\n",
              "   298,\n",
              "   300,\n",
              "   302,\n",
              "   304,\n",
              "   306,\n",
              "   308,\n",
              "   310,\n",
              "   312,\n",
              "   314,\n",
              "   316,\n",
              "   318,\n",
              "   320,\n",
              "   322,\n",
              "   324,\n",
              "   326,\n",
              "   328,\n",
              "   330,\n",
              "   332,\n",
              "   334,\n",
              "   336,\n",
              "   338,\n",
              "   340,\n",
              "   342,\n",
              "   344,\n",
              "   346,\n",
              "   348,\n",
              "   350,\n",
              "   352,\n",
              "   354,\n",
              "   356,\n",
              "   358,\n",
              "   360,\n",
              "   362,\n",
              "   364,\n",
              "   366,\n",
              "   368,\n",
              "   370,\n",
              "   372,\n",
              "   374,\n",
              "   376,\n",
              "   378,\n",
              "   380,\n",
              "   382,\n",
              "   384,\n",
              "   386,\n",
              "   388,\n",
              "   390,\n",
              "   392,\n",
              "   394,\n",
              "   396,\n",
              "   398,\n",
              "   400,\n",
              "   402,\n",
              "   404,\n",
              "   406,\n",
              "   408,\n",
              "   410,\n",
              "   412,\n",
              "   414,\n",
              "   416,\n",
              "   418,\n",
              "   420,\n",
              "   422,\n",
              "   424,\n",
              "   426,\n",
              "   428,\n",
              "   430,\n",
              "   432,\n",
              "   434,\n",
              "   436,\n",
              "   438,\n",
              "   440,\n",
              "   442,\n",
              "   444,\n",
              "   446,\n",
              "   448,\n",
              "   450,\n",
              "   452,\n",
              "   454,\n",
              "   456,\n",
              "   458,\n",
              "   460,\n",
              "   462,\n",
              "   464,\n",
              "   466,\n",
              "   468,\n",
              "   470,\n",
              "   472,\n",
              "   474,\n",
              "   476,\n",
              "   478,\n",
              "   480,\n",
              "   482,\n",
              "   484,\n",
              "   486,\n",
              "   488,\n",
              "   490,\n",
              "   492,\n",
              "   494,\n",
              "   496,\n",
              "   498,\n",
              "   500,\n",
              "   502,\n",
              "   504,\n",
              "   506,\n",
              "   508,\n",
              "   510,\n",
              "   512,\n",
              "   514,\n",
              "   516,\n",
              "   518,\n",
              "   520,\n",
              "   522,\n",
              "   524,\n",
              "   526,\n",
              "   528,\n",
              "   530,\n",
              "   532,\n",
              "   534,\n",
              "   536,\n",
              "   538,\n",
              "   540,\n",
              "   542,\n",
              "   544,\n",
              "   546,\n",
              "   548,\n",
              "   550,\n",
              "   552,\n",
              "   554,\n",
              "   556,\n",
              "   558,\n",
              "   560,\n",
              "   562,\n",
              "   564,\n",
              "   566,\n",
              "   568,\n",
              "   570,\n",
              "   572,\n",
              "   574,\n",
              "   576,\n",
              "   578,\n",
              "   580,\n",
              "   582,\n",
              "   584,\n",
              "   586,\n",
              "   588,\n",
              "   590,\n",
              "   592,\n",
              "   594,\n",
              "   596,\n",
              "   598,\n",
              "   600,\n",
              "   602,\n",
              "   604,\n",
              "   606,\n",
              "   608,\n",
              "   610,\n",
              "   612,\n",
              "   614,\n",
              "   616,\n",
              "   618,\n",
              "   620,\n",
              "   622,\n",
              "   624,\n",
              "   626,\n",
              "   628,\n",
              "   630,\n",
              "   632,\n",
              "   634,\n",
              "   636,\n",
              "   638,\n",
              "   640,\n",
              "   642,\n",
              "   644,\n",
              "   646,\n",
              "   648,\n",
              "   650,\n",
              "   652,\n",
              "   654,\n",
              "   656,\n",
              "   658,\n",
              "   660,\n",
              "   662,\n",
              "   664,\n",
              "   666,\n",
              "   668,\n",
              "   670,\n",
              "   672,\n",
              "   674,\n",
              "   676,\n",
              "   678,\n",
              "   680,\n",
              "   682,\n",
              "   684,\n",
              "   686,\n",
              "   688,\n",
              "   690,\n",
              "   692,\n",
              "   694,\n",
              "   696,\n",
              "   698,\n",
              "   700,\n",
              "   702,\n",
              "   704,\n",
              "   706,\n",
              "   708,\n",
              "   710,\n",
              "   712,\n",
              "   714,\n",
              "   716,\n",
              "   718,\n",
              "   720,\n",
              "   722,\n",
              "   724,\n",
              "   726,\n",
              "   728,\n",
              "   730,\n",
              "   732,\n",
              "   734,\n",
              "   736,\n",
              "   738,\n",
              "   740,\n",
              "   742,\n",
              "   744,\n",
              "   746,\n",
              "   748,\n",
              "   750,\n",
              "   752,\n",
              "   754,\n",
              "   756,\n",
              "   758,\n",
              "   760,\n",
              "   762,\n",
              "   764,\n",
              "   766,\n",
              "   768,\n",
              "   770,\n",
              "   772,\n",
              "   774,\n",
              "   776,\n",
              "   778,\n",
              "   780,\n",
              "   782,\n",
              "   784,\n",
              "   786,\n",
              "   788,\n",
              "   790,\n",
              "   792,\n",
              "   794,\n",
              "   796,\n",
              "   798,\n",
              "   800,\n",
              "   802,\n",
              "   804,\n",
              "   806,\n",
              "   808,\n",
              "   810,\n",
              "   812,\n",
              "   814,\n",
              "   816,\n",
              "   818,\n",
              "   820,\n",
              "   822,\n",
              "   824,\n",
              "   826,\n",
              "   828,\n",
              "   830,\n",
              "   832,\n",
              "   834,\n",
              "   836,\n",
              "   838,\n",
              "   840,\n",
              "   842,\n",
              "   844,\n",
              "   846,\n",
              "   848,\n",
              "   850,\n",
              "   852,\n",
              "   854,\n",
              "   856,\n",
              "   858,\n",
              "   860,\n",
              "   862,\n",
              "   864,\n",
              "   866,\n",
              "   868,\n",
              "   870,\n",
              "   872,\n",
              "   874,\n",
              "   876,\n",
              "   878,\n",
              "   880,\n",
              "   882,\n",
              "   884,\n",
              "   886,\n",
              "   888,\n",
              "   890,\n",
              "   892,\n",
              "   894,\n",
              "   896,\n",
              "   898,\n",
              "   900,\n",
              "   902,\n",
              "   904,\n",
              "   906,\n",
              "   908,\n",
              "   910,\n",
              "   912,\n",
              "   914,\n",
              "   916,\n",
              "   918,\n",
              "   920,\n",
              "   922,\n",
              "   924,\n",
              "   926,\n",
              "   928,\n",
              "   930,\n",
              "   932,\n",
              "   934,\n",
              "   936,\n",
              "   938,\n",
              "   940,\n",
              "   942,\n",
              "   944,\n",
              "   946,\n",
              "   948,\n",
              "   950,\n",
              "   952,\n",
              "   954,\n",
              "   956,\n",
              "   958,\n",
              "   960,\n",
              "   962,\n",
              "   964,\n",
              "   966,\n",
              "   968,\n",
              "   970,\n",
              "   972,\n",
              "   974,\n",
              "   976,\n",
              "   978,\n",
              "   980,\n",
              "   982,\n",
              "   984,\n",
              "   986,\n",
              "   988,\n",
              "   990,\n",
              "   992,\n",
              "   994,\n",
              "   996,\n",
              "   998,\n",
              "   1000]),\n",
              " (1,\n",
              "  [1,\n",
              "   3,\n",
              "   5,\n",
              "   7,\n",
              "   9,\n",
              "   11,\n",
              "   13,\n",
              "   15,\n",
              "   17,\n",
              "   19,\n",
              "   21,\n",
              "   23,\n",
              "   25,\n",
              "   27,\n",
              "   29,\n",
              "   31,\n",
              "   33,\n",
              "   35,\n",
              "   37,\n",
              "   39,\n",
              "   41,\n",
              "   43,\n",
              "   45,\n",
              "   47,\n",
              "   49,\n",
              "   51,\n",
              "   53,\n",
              "   55,\n",
              "   57,\n",
              "   59,\n",
              "   61,\n",
              "   63,\n",
              "   65,\n",
              "   67,\n",
              "   69,\n",
              "   71,\n",
              "   73,\n",
              "   75,\n",
              "   77,\n",
              "   79,\n",
              "   81,\n",
              "   83,\n",
              "   85,\n",
              "   87,\n",
              "   89,\n",
              "   91,\n",
              "   93,\n",
              "   95,\n",
              "   97,\n",
              "   99,\n",
              "   101,\n",
              "   103,\n",
              "   105,\n",
              "   107,\n",
              "   109,\n",
              "   111,\n",
              "   113,\n",
              "   115,\n",
              "   117,\n",
              "   119,\n",
              "   121,\n",
              "   123,\n",
              "   125,\n",
              "   127,\n",
              "   129,\n",
              "   131,\n",
              "   133,\n",
              "   135,\n",
              "   137,\n",
              "   139,\n",
              "   141,\n",
              "   143,\n",
              "   145,\n",
              "   147,\n",
              "   149,\n",
              "   151,\n",
              "   153,\n",
              "   155,\n",
              "   157,\n",
              "   159,\n",
              "   161,\n",
              "   163,\n",
              "   165,\n",
              "   167,\n",
              "   169,\n",
              "   171,\n",
              "   173,\n",
              "   175,\n",
              "   177,\n",
              "   179,\n",
              "   181,\n",
              "   183,\n",
              "   185,\n",
              "   187,\n",
              "   189,\n",
              "   191,\n",
              "   193,\n",
              "   195,\n",
              "   197,\n",
              "   199,\n",
              "   201,\n",
              "   203,\n",
              "   205,\n",
              "   207,\n",
              "   209,\n",
              "   211,\n",
              "   213,\n",
              "   215,\n",
              "   217,\n",
              "   219,\n",
              "   221,\n",
              "   223,\n",
              "   225,\n",
              "   227,\n",
              "   229,\n",
              "   231,\n",
              "   233,\n",
              "   235,\n",
              "   237,\n",
              "   239,\n",
              "   241,\n",
              "   243,\n",
              "   245,\n",
              "   247,\n",
              "   249,\n",
              "   251,\n",
              "   253,\n",
              "   255,\n",
              "   257,\n",
              "   259,\n",
              "   261,\n",
              "   263,\n",
              "   265,\n",
              "   267,\n",
              "   269,\n",
              "   271,\n",
              "   273,\n",
              "   275,\n",
              "   277,\n",
              "   279,\n",
              "   281,\n",
              "   283,\n",
              "   285,\n",
              "   287,\n",
              "   289,\n",
              "   291,\n",
              "   293,\n",
              "   295,\n",
              "   297,\n",
              "   299,\n",
              "   301,\n",
              "   303,\n",
              "   305,\n",
              "   307,\n",
              "   309,\n",
              "   311,\n",
              "   313,\n",
              "   315,\n",
              "   317,\n",
              "   319,\n",
              "   321,\n",
              "   323,\n",
              "   325,\n",
              "   327,\n",
              "   329,\n",
              "   331,\n",
              "   333,\n",
              "   335,\n",
              "   337,\n",
              "   339,\n",
              "   341,\n",
              "   343,\n",
              "   345,\n",
              "   347,\n",
              "   349,\n",
              "   351,\n",
              "   353,\n",
              "   355,\n",
              "   357,\n",
              "   359,\n",
              "   361,\n",
              "   363,\n",
              "   365,\n",
              "   367,\n",
              "   369,\n",
              "   371,\n",
              "   373,\n",
              "   375,\n",
              "   377,\n",
              "   379,\n",
              "   381,\n",
              "   383,\n",
              "   385,\n",
              "   387,\n",
              "   389,\n",
              "   391,\n",
              "   393,\n",
              "   395,\n",
              "   397,\n",
              "   399,\n",
              "   401,\n",
              "   403,\n",
              "   405,\n",
              "   407,\n",
              "   409,\n",
              "   411,\n",
              "   413,\n",
              "   415,\n",
              "   417,\n",
              "   419,\n",
              "   421,\n",
              "   423,\n",
              "   425,\n",
              "   427,\n",
              "   429,\n",
              "   431,\n",
              "   433,\n",
              "   435,\n",
              "   437,\n",
              "   439,\n",
              "   441,\n",
              "   443,\n",
              "   445,\n",
              "   447,\n",
              "   449,\n",
              "   451,\n",
              "   453,\n",
              "   455,\n",
              "   457,\n",
              "   459,\n",
              "   461,\n",
              "   463,\n",
              "   465,\n",
              "   467,\n",
              "   469,\n",
              "   471,\n",
              "   473,\n",
              "   475,\n",
              "   477,\n",
              "   479,\n",
              "   481,\n",
              "   483,\n",
              "   485,\n",
              "   487,\n",
              "   489,\n",
              "   491,\n",
              "   493,\n",
              "   495,\n",
              "   497,\n",
              "   499,\n",
              "   501,\n",
              "   503,\n",
              "   505,\n",
              "   507,\n",
              "   509,\n",
              "   511,\n",
              "   513,\n",
              "   515,\n",
              "   517,\n",
              "   519,\n",
              "   521,\n",
              "   523,\n",
              "   525,\n",
              "   527,\n",
              "   529,\n",
              "   531,\n",
              "   533,\n",
              "   535,\n",
              "   537,\n",
              "   539,\n",
              "   541,\n",
              "   543,\n",
              "   545,\n",
              "   547,\n",
              "   549,\n",
              "   551,\n",
              "   553,\n",
              "   555,\n",
              "   557,\n",
              "   559,\n",
              "   561,\n",
              "   563,\n",
              "   565,\n",
              "   567,\n",
              "   569,\n",
              "   571,\n",
              "   573,\n",
              "   575,\n",
              "   577,\n",
              "   579,\n",
              "   581,\n",
              "   583,\n",
              "   585,\n",
              "   587,\n",
              "   589,\n",
              "   591,\n",
              "   593,\n",
              "   595,\n",
              "   597,\n",
              "   599,\n",
              "   601,\n",
              "   603,\n",
              "   605,\n",
              "   607,\n",
              "   609,\n",
              "   611,\n",
              "   613,\n",
              "   615,\n",
              "   617,\n",
              "   619,\n",
              "   621,\n",
              "   623,\n",
              "   625,\n",
              "   627,\n",
              "   629,\n",
              "   631,\n",
              "   633,\n",
              "   635,\n",
              "   637,\n",
              "   639,\n",
              "   641,\n",
              "   643,\n",
              "   645,\n",
              "   647,\n",
              "   649,\n",
              "   651,\n",
              "   653,\n",
              "   655,\n",
              "   657,\n",
              "   659,\n",
              "   661,\n",
              "   663,\n",
              "   665,\n",
              "   667,\n",
              "   669,\n",
              "   671,\n",
              "   673,\n",
              "   675,\n",
              "   677,\n",
              "   679,\n",
              "   681,\n",
              "   683,\n",
              "   685,\n",
              "   687,\n",
              "   689,\n",
              "   691,\n",
              "   693,\n",
              "   695,\n",
              "   697,\n",
              "   699,\n",
              "   701,\n",
              "   703,\n",
              "   705,\n",
              "   707,\n",
              "   709,\n",
              "   711,\n",
              "   713,\n",
              "   715,\n",
              "   717,\n",
              "   719,\n",
              "   721,\n",
              "   723,\n",
              "   725,\n",
              "   727,\n",
              "   729,\n",
              "   731,\n",
              "   733,\n",
              "   735,\n",
              "   737,\n",
              "   739,\n",
              "   741,\n",
              "   743,\n",
              "   745,\n",
              "   747,\n",
              "   749,\n",
              "   751,\n",
              "   753,\n",
              "   755,\n",
              "   757,\n",
              "   759,\n",
              "   761,\n",
              "   763,\n",
              "   765,\n",
              "   767,\n",
              "   769,\n",
              "   771,\n",
              "   773,\n",
              "   775,\n",
              "   777,\n",
              "   779,\n",
              "   781,\n",
              "   783,\n",
              "   785,\n",
              "   787,\n",
              "   789,\n",
              "   791,\n",
              "   793,\n",
              "   795,\n",
              "   797,\n",
              "   799,\n",
              "   801,\n",
              "   803,\n",
              "   805,\n",
              "   807,\n",
              "   809,\n",
              "   811,\n",
              "   813,\n",
              "   815,\n",
              "   817,\n",
              "   819,\n",
              "   821,\n",
              "   823,\n",
              "   825,\n",
              "   827,\n",
              "   829,\n",
              "   831,\n",
              "   833,\n",
              "   835,\n",
              "   837,\n",
              "   839,\n",
              "   841,\n",
              "   843,\n",
              "   845,\n",
              "   847,\n",
              "   849,\n",
              "   851,\n",
              "   853,\n",
              "   855,\n",
              "   857,\n",
              "   859,\n",
              "   861,\n",
              "   863,\n",
              "   865,\n",
              "   867,\n",
              "   869,\n",
              "   871,\n",
              "   873,\n",
              "   875,\n",
              "   877,\n",
              "   879,\n",
              "   881,\n",
              "   883,\n",
              "   885,\n",
              "   887,\n",
              "   889,\n",
              "   891,\n",
              "   893,\n",
              "   895,\n",
              "   897,\n",
              "   899,\n",
              "   901,\n",
              "   903,\n",
              "   905,\n",
              "   907,\n",
              "   909,\n",
              "   911,\n",
              "   913,\n",
              "   915,\n",
              "   917,\n",
              "   919,\n",
              "   921,\n",
              "   923,\n",
              "   925,\n",
              "   927,\n",
              "   929,\n",
              "   931,\n",
              "   933,\n",
              "   935,\n",
              "   937,\n",
              "   939,\n",
              "   941,\n",
              "   943,\n",
              "   945,\n",
              "   947,\n",
              "   949,\n",
              "   951,\n",
              "   953,\n",
              "   955,\n",
              "   957,\n",
              "   959,\n",
              "   961,\n",
              "   963,\n",
              "   965,\n",
              "   967,\n",
              "   969,\n",
              "   971,\n",
              "   973,\n",
              "   975,\n",
              "   977,\n",
              "   979,\n",
              "   981,\n",
              "   983,\n",
              "   985,\n",
              "   987,\n",
              "   989,\n",
              "   991,\n",
              "   993,\n",
              "   995,\n",
              "   997,\n",
              "   999])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zs5j3VRZJBZL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "94df4f67-113a-421b-9222-0191a9aa555c"
      },
      "source": [
        "#Ejecutamos el collect sin el 2do MAP solo para ver...:\n",
        "integersListRDD.map(lambda x: (x % 2, x)).groupByKey().collect()\n",
        "\n",
        "#Vemos que para la clave 0 y 1 tenemos 2 iterables pero no podemos ver el contenido, por eso antes lo transformamos a list."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, <pyspark.resultiterable.ResultIterable at 0x7ff51409e470>),\n",
              " (1, <pyspark.resultiterable.ResultIterable at 0x7ff51409e390>)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_URCZ87zAcSj",
        "colab_type": "text"
      },
      "source": [
        "## Distinct\n",
        "\n",
        "Elimina registros duplicados (todo el registro debe coincidir.. osea que TODO el registro debe ser igual para que la función Distinct lo pueda eliminar)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcLF3Se1Il4k",
        "colab_type": "text"
      },
      "source": [
        "Se lo aplicamos a la lista integersFlat (el RDD trás aplicar flatMap que vimos anteriormente, donde teníamos 3000 números/registros) para obtener así los registros únicos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbVHrMYgCv65",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "70d85c0c-a620-43bb-aa65-9582ffb874f6"
      },
      "source": [
        "integersFlat.distinct().count()\n",
        "#Son 1002 registros ya que teniamos los números del 1 al 1000, el 0 y el 1001. "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1002"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bl2uMtBy-CxH",
        "colab_type": "text"
      },
      "source": [
        "# 4- Más ejemplos de transformaciones y acciones con los textos de Shakespeare (con uso de wordsCount)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSNsuSWUVzjL",
        "colab_type": "text"
      },
      "source": [
        "## Leo de a líneas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVzGjkUPJm6X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lines = spark.sparkContext.textFile('/content/drive/My Drive/Colab Notebooks/UBA/5-SPARK/Notebook/Txt Shekspeare utilizado/s.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwuDYbFQV3wk",
        "colab_type": "text"
      },
      "source": [
        "## Cantidad de líneas totales"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMydwl-2JoRX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "78b6e9f8-fc69-48ff-fc76-3be46197fd82"
      },
      "source": [
        "lines.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "124614"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZEeqhf_V7eM",
        "colab_type": "text"
      },
      "source": [
        "## Primeras 10 líneas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQaWh8CnJqlY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "af6d8f9b-009b-45eb-994d-8836db5526ba"
      },
      "source": [
        "lines.take(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1609',\n",
              " '',\n",
              " 'THE SONNETS',\n",
              " '',\n",
              " 'by William Shakespeare',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '                     1',\n",
              " '  From fairest creatures we desire increase,']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vsAsbU7V_h3",
        "colab_type": "text"
      },
      "source": [
        "## Obtengo las palabras de todas las líneas (flatMap)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOOPFmCh4HBJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = lines.flatMap(lambda x: x.split())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoBtYMOkJ4w2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "dc28c1d7-0c02-419e-b983-1b87b8f3eeeb"
      },
      "source": [
        "words.take(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1609',\n",
              " 'THE',\n",
              " 'SONNETS',\n",
              " 'by',\n",
              " 'William',\n",
              " 'Shakespeare',\n",
              " '1',\n",
              " 'From',\n",
              " 'fairest',\n",
              " 'creatures']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRAZmoOzNWgE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "81cf69b6-be15-41a6-b745-917f0e0b21a6"
      },
      "source": [
        "words.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "902892"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9M-FlX5DWK0d",
        "colab_type": "text"
      },
      "source": [
        "## Contando palabras (reduceByKey)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ls1O6FLo-IQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wordsCount = words.map(lambda x: (x.lower(),1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRgS4oUlKDBT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "9afc3857-0d0f-4c1c-92b3-3ebddb3e97d9"
      },
      "source": [
        "wordsCount.take(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('1609', 1),\n",
              " ('the', 1),\n",
              " ('sonnets', 1),\n",
              " ('by', 1),\n",
              " ('william', 1),\n",
              " ('shakespeare', 1),\n",
              " ('1', 1),\n",
              " ('from', 1),\n",
              " ('fairest', 1),\n",
              " ('creatures', 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6aAGd8UKANh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wordsCounted = wordsCount.reduceByKey(lambda x,y: x+y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hn_lW0hrKr2N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "ea633416-f337-4234-9348-c401a5ca4557"
      },
      "source": [
        "wordsCounted.take(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('shakespeare', 258),\n",
              " ('1', 13),\n",
              " ('fairest', 39),\n",
              " ('creatures', 27),\n",
              " ('we', 3210),\n",
              " ('increase,', 9),\n",
              " ('thereby', 21),\n",
              " (\"beauty's\", 30),\n",
              " ('rose', 44),\n",
              " ('never', 959)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahh0On2NKtj1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "094c292a-fe82-426b-a392-29a7fb2b2100"
      },
      "source": [
        "wordsCounted.takeOrdered(10, lambda x: -x[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 27681),\n",
              " ('and', 26066),\n",
              " ('i', 19540),\n",
              " ('to', 18737),\n",
              " ('of', 18084),\n",
              " ('a', 14424),\n",
              " ('my', 12456),\n",
              " ('in', 10721),\n",
              " ('you', 10666),\n",
              " ('that', 10489)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPpLRI_iW1zj",
        "colab_type": "text"
      },
      "source": [
        "### Mal uso de groupByKey"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8j0f4cPW5Ct",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "fe77d117-6951-4fb5-922f-8549a04ee798"
      },
      "source": [
        "wordsCount.groupByKey().takeOrdered(10, lambda x: -1 * len(x[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', <pyspark.resultiterable.ResultIterable at 0x7ff51409eac8>),\n",
              " ('and', <pyspark.resultiterable.ResultIterable at 0x7ff5140f70b8>),\n",
              " ('i', <pyspark.resultiterable.ResultIterable at 0x7ff51409e4a8>),\n",
              " ('to', <pyspark.resultiterable.ResultIterable at 0x7ff5140f7390>),\n",
              " ('of', <pyspark.resultiterable.ResultIterable at 0x7ff51409e710>),\n",
              " ('a', <pyspark.resultiterable.ResultIterable at 0x7ff5140f71d0>),\n",
              " ('my', <pyspark.resultiterable.ResultIterable at 0x7ff5140f7978>),\n",
              " ('in', <pyspark.resultiterable.ResultIterable at 0x7ff51409e128>),\n",
              " ('you', <pyspark.resultiterable.ResultIterable at 0x7ff5140f79e8>),\n",
              " ('that', <pyspark.resultiterable.ResultIterable at 0x7ff5140f7ac8>)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOEXpY5D5Pu0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f8ed6078-ba60-41cf-b0e2-00546bbefbf1"
      },
      "source": [
        "wordsCount.groupByKey().map(lambda a: (a[0], list(a[1]))).take(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('shakespeare',\n",
              "  [1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1]),\n",
              " ('1', [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " ('fairest',\n",
              "  [1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1]),\n",
              " ('creatures',\n",
              "  [1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1]),\n",
              " ('we',\n",
              "  [1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   ...])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AR1N2D4fXpLn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "562a19b8-b69f-41df-b1e4-2cb7a134c389"
      },
      "source": [
        "wordsCount.groupByKey().filter(lambda x: len(x[1]) < 5).map(lambda a: (a[0], list(a[1]))).take(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('riper', [1, 1, 1]),\n",
              " ('memory:', [1]),\n",
              " (\"feed'st\", [1, 1, 1]),\n",
              " (\"light's\", [1]),\n",
              " ('fuel,', [1])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QDBwG7ZYVmV",
        "colab_type": "text"
      },
      "source": [
        "## Palabra más larga (reduce)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-tIGKUtYbeg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "182aacec-5edf-48a3-dc1d-ea45b6367745"
      },
      "source": [
        "words.reduce(lambda a, b: a if (len(a) > len(b)) else b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'http://www.ibiblio.org/gutenberg/etext06'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWyAXyTfYnL2",
        "colab_type": "text"
      },
      "source": [
        "## Palabras que empiezan con a (filter)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lL3AThZsYtcp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wordsA = words.filter(lambda word: word.startswith('a'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAeEHwp9Y1e9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "9a126604-1e7f-43c9-bc76-5e2c3ee5d419"
      },
      "source": [
        "wordsA.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "63676"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqR7v7k1Y39H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "d06873d1-bdf0-43f8-e1db-44cd33fd31d4"
      },
      "source": [
        "wordsA.take(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['as', 'a', 'abundance', 'art', 'and', 'a', 'asked,', 'all', 'all', 'an']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oh21OigvZBRD",
        "colab_type": "text"
      },
      "source": [
        "## Palabras únicas que empiezan con a (distinct)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rI4olhzfZEkV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "0041082b-5c60-458d-dc5a-78e04e2e89c9"
      },
      "source": [
        "wordsA.distinct().count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2688"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpKemb9lZOoa",
        "colab_type": "text"
      },
      "source": [
        "## Cantidad de palabras por frecuencia de repetición ordenados (sortByKey)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7WAUcp76rvF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "139f1cf7-af51-4a09-89f8-8795421da712"
      },
      "source": [
        "wordsCounted.take(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('shakespeare', 258),\n",
              " ('1', 13),\n",
              " ('fairest', 39),\n",
              " ('creatures', 27),\n",
              " ('we', 3210)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txZj8VR1K0MY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wordsFreq = wordsCounted.map(lambda x: (x[1],1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88ZPvuP4LgBt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "5315f23b-a4cb-418e-c052-e6d92492cbe6"
      },
      "source": [
        "wordsFreq.take(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(258, 1),\n",
              " (13, 1),\n",
              " (39, 1),\n",
              " (27, 1),\n",
              " (3210, 1),\n",
              " (9, 1),\n",
              " (21, 1),\n",
              " (30, 1),\n",
              " (44, 1),\n",
              " (959, 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGd12kyHZdIS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "9aa13d80-edfb-41dc-9223-0fe45a966749"
      },
      "source": [
        "wordsFreq.reduceByKey(lambda a,b: a+b).sortByKey().take(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 31072),\n",
              " (2, 8493),\n",
              " (3, 4342),\n",
              " (4, 2659),\n",
              " (5, 1822),\n",
              " (6, 1338),\n",
              " (7, 1053),\n",
              " (8, 779),\n",
              " (9, 700),\n",
              " (10, 549)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhA9tmhZLuZF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "499453b0-ec51-4168-9976-e1f3f504a06f"
      },
      "source": [
        "wordsFreq.reduceByKey(lambda a,b: a+b).takeOrdered(10, lambda x: -x[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 31072),\n",
              " (2, 8493),\n",
              " (3, 4342),\n",
              " (4, 2659),\n",
              " (5, 1822),\n",
              " (6, 1338),\n",
              " (7, 1053),\n",
              " (8, 779),\n",
              " (9, 700),\n",
              " (10, 549)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqrkX2Jh73fR",
        "colab_type": "text"
      },
      "source": [
        "# 5-Transformaciones entre dos RDD (con uso de Joins).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "legQOraf7-ai",
        "colab_type": "text"
      },
      "source": [
        "## Union"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F76c0ngp8JhD",
        "colab_type": "text"
      },
      "source": [
        "Obtiene la unión entre dos RDD."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMqSaDhQOA0V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "4b02b37b-6f93-49f4-f4fa-1cda7893f554"
      },
      "source": [
        "integersList2 = range(501,1501)\n",
        "len(integersList2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDB8R4mp9SxM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "integersList2RDD = sc.parallelize(integersList2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4jCnCS49bot",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "c03fe527-0630-4ed6-8cab-646bf656815b"
      },
      "source": [
        "integersList2RDD.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jB-WFpLB9dWF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "3e37b261-875b-4ae5-aa41-36dea70b284e"
      },
      "source": [
        "integersListRDD.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70C8rrq49lUI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "union = integersListRDD.union(integersList2RDD)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9lL1l6g9o8y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "cc751dfe-61dc-46af-fa3b-d58e132f3aca"
      },
      "source": [
        "union.take(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfwo3GW99q0L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "b95a92db-2d7a-45fb-9f66-e656442002b4"
      },
      "source": [
        "union.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJ18HxVP9uSW",
        "colab_type": "text"
      },
      "source": [
        "## Intersection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6bSa4ml93CA",
        "colab_type": "text"
      },
      "source": [
        "Intersección entre dos RDD."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJO8WJ1D9sEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "intersection = integersListRDD.intersection(integersList2RDD)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQ2IVU3T9-cC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "fae1bb7a-aafd-46cc-fdaa-81d877d846a2"
      },
      "source": [
        "intersection.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZheIKRNjOio",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "72199629-4eb4-474c-8853-5ffc7c02a21b"
      },
      "source": [
        "intersection.take(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[510, 520, 530, 540, 550, 560, 570, 580, 590, 600]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buyC_d50jSPQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "949e2a49-e201-42bd-b71a-b86bef253406"
      },
      "source": [
        "intersection.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[510,\n",
              " 520,\n",
              " 530,\n",
              " 540,\n",
              " 550,\n",
              " 560,\n",
              " 570,\n",
              " 580,\n",
              " 590,\n",
              " 600,\n",
              " 610,\n",
              " 620,\n",
              " 630,\n",
              " 640,\n",
              " 650,\n",
              " 660,\n",
              " 670,\n",
              " 680,\n",
              " 690,\n",
              " 700,\n",
              " 710,\n",
              " 720,\n",
              " 730,\n",
              " 740,\n",
              " 750,\n",
              " 760,\n",
              " 770,\n",
              " 780,\n",
              " 790,\n",
              " 800,\n",
              " 810,\n",
              " 820,\n",
              " 830,\n",
              " 840,\n",
              " 850,\n",
              " 860,\n",
              " 870,\n",
              " 880,\n",
              " 890,\n",
              " 900,\n",
              " 910,\n",
              " 920,\n",
              " 930,\n",
              " 940,\n",
              " 950,\n",
              " 960,\n",
              " 970,\n",
              " 980,\n",
              " 990,\n",
              " 1000,\n",
              " 501,\n",
              " 511,\n",
              " 521,\n",
              " 531,\n",
              " 541,\n",
              " 551,\n",
              " 561,\n",
              " 571,\n",
              " 581,\n",
              " 591,\n",
              " 601,\n",
              " 611,\n",
              " 621,\n",
              " 631,\n",
              " 641,\n",
              " 651,\n",
              " 661,\n",
              " 671,\n",
              " 681,\n",
              " 691,\n",
              " 701,\n",
              " 711,\n",
              " 721,\n",
              " 731,\n",
              " 741,\n",
              " 751,\n",
              " 761,\n",
              " 771,\n",
              " 781,\n",
              " 791,\n",
              " 801,\n",
              " 811,\n",
              " 821,\n",
              " 831,\n",
              " 841,\n",
              " 851,\n",
              " 861,\n",
              " 871,\n",
              " 881,\n",
              " 891,\n",
              " 901,\n",
              " 911,\n",
              " 921,\n",
              " 931,\n",
              " 941,\n",
              " 951,\n",
              " 961,\n",
              " 971,\n",
              " 981,\n",
              " 991,\n",
              " 502,\n",
              " 512,\n",
              " 522,\n",
              " 532,\n",
              " 542,\n",
              " 552,\n",
              " 562,\n",
              " 572,\n",
              " 582,\n",
              " 592,\n",
              " 602,\n",
              " 612,\n",
              " 622,\n",
              " 632,\n",
              " 642,\n",
              " 652,\n",
              " 662,\n",
              " 672,\n",
              " 682,\n",
              " 692,\n",
              " 702,\n",
              " 712,\n",
              " 722,\n",
              " 732,\n",
              " 742,\n",
              " 752,\n",
              " 762,\n",
              " 772,\n",
              " 782,\n",
              " 792,\n",
              " 802,\n",
              " 812,\n",
              " 822,\n",
              " 832,\n",
              " 842,\n",
              " 852,\n",
              " 862,\n",
              " 872,\n",
              " 882,\n",
              " 892,\n",
              " 902,\n",
              " 912,\n",
              " 922,\n",
              " 932,\n",
              " 942,\n",
              " 952,\n",
              " 962,\n",
              " 972,\n",
              " 982,\n",
              " 992,\n",
              " 503,\n",
              " 513,\n",
              " 523,\n",
              " 533,\n",
              " 543,\n",
              " 553,\n",
              " 563,\n",
              " 573,\n",
              " 583,\n",
              " 593,\n",
              " 603,\n",
              " 613,\n",
              " 623,\n",
              " 633,\n",
              " 643,\n",
              " 653,\n",
              " 663,\n",
              " 673,\n",
              " 683,\n",
              " 693,\n",
              " 703,\n",
              " 713,\n",
              " 723,\n",
              " 733,\n",
              " 743,\n",
              " 753,\n",
              " 763,\n",
              " 773,\n",
              " 783,\n",
              " 793,\n",
              " 803,\n",
              " 813,\n",
              " 823,\n",
              " 833,\n",
              " 843,\n",
              " 853,\n",
              " 863,\n",
              " 873,\n",
              " 883,\n",
              " 893,\n",
              " 903,\n",
              " 913,\n",
              " 923,\n",
              " 933,\n",
              " 943,\n",
              " 953,\n",
              " 963,\n",
              " 973,\n",
              " 983,\n",
              " 993,\n",
              " 504,\n",
              " 514,\n",
              " 524,\n",
              " 534,\n",
              " 544,\n",
              " 554,\n",
              " 564,\n",
              " 574,\n",
              " 584,\n",
              " 594,\n",
              " 604,\n",
              " 614,\n",
              " 624,\n",
              " 634,\n",
              " 644,\n",
              " 654,\n",
              " 664,\n",
              " 674,\n",
              " 684,\n",
              " 694,\n",
              " 704,\n",
              " 714,\n",
              " 724,\n",
              " 734,\n",
              " 744,\n",
              " 754,\n",
              " 764,\n",
              " 774,\n",
              " 784,\n",
              " 794,\n",
              " 804,\n",
              " 814,\n",
              " 824,\n",
              " 834,\n",
              " 844,\n",
              " 854,\n",
              " 864,\n",
              " 874,\n",
              " 884,\n",
              " 894,\n",
              " 904,\n",
              " 914,\n",
              " 924,\n",
              " 934,\n",
              " 944,\n",
              " 954,\n",
              " 964,\n",
              " 974,\n",
              " 984,\n",
              " 994,\n",
              " 505,\n",
              " 515,\n",
              " 525,\n",
              " 535,\n",
              " 545,\n",
              " 555,\n",
              " 565,\n",
              " 575,\n",
              " 585,\n",
              " 595,\n",
              " 605,\n",
              " 615,\n",
              " 625,\n",
              " 635,\n",
              " 645,\n",
              " 655,\n",
              " 665,\n",
              " 675,\n",
              " 685,\n",
              " 695,\n",
              " 705,\n",
              " 715,\n",
              " 725,\n",
              " 735,\n",
              " 745,\n",
              " 755,\n",
              " 765,\n",
              " 775,\n",
              " 785,\n",
              " 795,\n",
              " 805,\n",
              " 815,\n",
              " 825,\n",
              " 835,\n",
              " 845,\n",
              " 855,\n",
              " 865,\n",
              " 875,\n",
              " 885,\n",
              " 895,\n",
              " 905,\n",
              " 915,\n",
              " 925,\n",
              " 935,\n",
              " 945,\n",
              " 955,\n",
              " 965,\n",
              " 975,\n",
              " 985,\n",
              " 995,\n",
              " 506,\n",
              " 516,\n",
              " 526,\n",
              " 536,\n",
              " 546,\n",
              " 556,\n",
              " 566,\n",
              " 576,\n",
              " 586,\n",
              " 596,\n",
              " 606,\n",
              " 616,\n",
              " 626,\n",
              " 636,\n",
              " 646,\n",
              " 656,\n",
              " 666,\n",
              " 676,\n",
              " 686,\n",
              " 696,\n",
              " 706,\n",
              " 716,\n",
              " 726,\n",
              " 736,\n",
              " 746,\n",
              " 756,\n",
              " 766,\n",
              " 776,\n",
              " 786,\n",
              " 796,\n",
              " 806,\n",
              " 816,\n",
              " 826,\n",
              " 836,\n",
              " 846,\n",
              " 856,\n",
              " 866,\n",
              " 876,\n",
              " 886,\n",
              " 896,\n",
              " 906,\n",
              " 916,\n",
              " 926,\n",
              " 936,\n",
              " 946,\n",
              " 956,\n",
              " 966,\n",
              " 976,\n",
              " 986,\n",
              " 996,\n",
              " 507,\n",
              " 517,\n",
              " 527,\n",
              " 537,\n",
              " 547,\n",
              " 557,\n",
              " 567,\n",
              " 577,\n",
              " 587,\n",
              " 597,\n",
              " 607,\n",
              " 617,\n",
              " 627,\n",
              " 637,\n",
              " 647,\n",
              " 657,\n",
              " 667,\n",
              " 677,\n",
              " 687,\n",
              " 697,\n",
              " 707,\n",
              " 717,\n",
              " 727,\n",
              " 737,\n",
              " 747,\n",
              " 757,\n",
              " 767,\n",
              " 777,\n",
              " 787,\n",
              " 797,\n",
              " 807,\n",
              " 817,\n",
              " 827,\n",
              " 837,\n",
              " 847,\n",
              " 857,\n",
              " 867,\n",
              " 877,\n",
              " 887,\n",
              " 897,\n",
              " 907,\n",
              " 917,\n",
              " 927,\n",
              " 937,\n",
              " 947,\n",
              " 957,\n",
              " 967,\n",
              " 977,\n",
              " 987,\n",
              " 997,\n",
              " 508,\n",
              " 518,\n",
              " 528,\n",
              " 538,\n",
              " 548,\n",
              " 558,\n",
              " 568,\n",
              " 578,\n",
              " 588,\n",
              " 598,\n",
              " 608,\n",
              " 618,\n",
              " 628,\n",
              " 638,\n",
              " 648,\n",
              " 658,\n",
              " 668,\n",
              " 678,\n",
              " 688,\n",
              " 698,\n",
              " 708,\n",
              " 718,\n",
              " 728,\n",
              " 738,\n",
              " 748,\n",
              " 758,\n",
              " 768,\n",
              " 778,\n",
              " 788,\n",
              " 798,\n",
              " 808,\n",
              " 818,\n",
              " 828,\n",
              " 838,\n",
              " 848,\n",
              " 858,\n",
              " 868,\n",
              " 878,\n",
              " 888,\n",
              " 898,\n",
              " 908,\n",
              " 918,\n",
              " 928,\n",
              " 938,\n",
              " 948,\n",
              " 958,\n",
              " 968,\n",
              " 978,\n",
              " 988,\n",
              " 998,\n",
              " 509,\n",
              " 519,\n",
              " 529,\n",
              " 539,\n",
              " 549,\n",
              " 559,\n",
              " 569,\n",
              " 579,\n",
              " 589,\n",
              " 599,\n",
              " 609,\n",
              " 619,\n",
              " 629,\n",
              " 639,\n",
              " 649,\n",
              " 659,\n",
              " 669,\n",
              " 679,\n",
              " 689,\n",
              " 699,\n",
              " 709,\n",
              " 719,\n",
              " 729,\n",
              " 739,\n",
              " 749,\n",
              " 759,\n",
              " 769,\n",
              " 779,\n",
              " 789,\n",
              " 799,\n",
              " 809,\n",
              " 819,\n",
              " 829,\n",
              " 839,\n",
              " 849,\n",
              " 859,\n",
              " 869,\n",
              " 879,\n",
              " 889,\n",
              " 899,\n",
              " 909,\n",
              " 919,\n",
              " 929,\n",
              " 939,\n",
              " 949,\n",
              " 959,\n",
              " 969,\n",
              " 979,\n",
              " 989,\n",
              " 999]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28l3dlYxJzyi",
        "colab_type": "text"
      },
      "source": [
        "## Subtract"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WbPFo35J3tE",
        "colab_type": "text"
      },
      "source": [
        "Elimina del primer RDD los registros que aparezcan en el segundo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GLXtqb9J8ev",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "subtract = integersListRDD.subtract(integersList2RDD)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0zdfroiKHU8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "538975e9-d045-4d1d-e0cf-ed65c49a7fd0"
      },
      "source": [
        "subtract.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkIvM1Tijnaz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "29337e49-72af-4140-dd56-4f690c584b79"
      },
      "source": [
        "subtract.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[10,\n",
              " 20,\n",
              " 30,\n",
              " 40,\n",
              " 50,\n",
              " 60,\n",
              " 70,\n",
              " 80,\n",
              " 90,\n",
              " 100,\n",
              " 110,\n",
              " 120,\n",
              " 130,\n",
              " 140,\n",
              " 150,\n",
              " 160,\n",
              " 170,\n",
              " 180,\n",
              " 190,\n",
              " 200,\n",
              " 210,\n",
              " 220,\n",
              " 230,\n",
              " 240,\n",
              " 250,\n",
              " 260,\n",
              " 270,\n",
              " 280,\n",
              " 290,\n",
              " 300,\n",
              " 310,\n",
              " 320,\n",
              " 330,\n",
              " 340,\n",
              " 350,\n",
              " 360,\n",
              " 370,\n",
              " 380,\n",
              " 390,\n",
              " 400,\n",
              " 410,\n",
              " 420,\n",
              " 430,\n",
              " 440,\n",
              " 450,\n",
              " 460,\n",
              " 470,\n",
              " 480,\n",
              " 490,\n",
              " 500,\n",
              " 1,\n",
              " 11,\n",
              " 21,\n",
              " 31,\n",
              " 41,\n",
              " 51,\n",
              " 61,\n",
              " 71,\n",
              " 81,\n",
              " 91,\n",
              " 101,\n",
              " 111,\n",
              " 121,\n",
              " 131,\n",
              " 141,\n",
              " 151,\n",
              " 161,\n",
              " 171,\n",
              " 181,\n",
              " 191,\n",
              " 201,\n",
              " 211,\n",
              " 221,\n",
              " 231,\n",
              " 241,\n",
              " 251,\n",
              " 261,\n",
              " 271,\n",
              " 281,\n",
              " 291,\n",
              " 301,\n",
              " 311,\n",
              " 321,\n",
              " 331,\n",
              " 341,\n",
              " 351,\n",
              " 361,\n",
              " 371,\n",
              " 381,\n",
              " 391,\n",
              " 401,\n",
              " 411,\n",
              " 421,\n",
              " 431,\n",
              " 441,\n",
              " 451,\n",
              " 461,\n",
              " 471,\n",
              " 481,\n",
              " 491,\n",
              " 2,\n",
              " 12,\n",
              " 22,\n",
              " 32,\n",
              " 42,\n",
              " 52,\n",
              " 62,\n",
              " 72,\n",
              " 82,\n",
              " 92,\n",
              " 102,\n",
              " 112,\n",
              " 122,\n",
              " 132,\n",
              " 142,\n",
              " 152,\n",
              " 162,\n",
              " 172,\n",
              " 182,\n",
              " 192,\n",
              " 202,\n",
              " 212,\n",
              " 222,\n",
              " 232,\n",
              " 242,\n",
              " 252,\n",
              " 262,\n",
              " 272,\n",
              " 282,\n",
              " 292,\n",
              " 302,\n",
              " 312,\n",
              " 322,\n",
              " 332,\n",
              " 342,\n",
              " 352,\n",
              " 362,\n",
              " 372,\n",
              " 382,\n",
              " 392,\n",
              " 402,\n",
              " 412,\n",
              " 422,\n",
              " 432,\n",
              " 442,\n",
              " 452,\n",
              " 462,\n",
              " 472,\n",
              " 482,\n",
              " 492,\n",
              " 3,\n",
              " 13,\n",
              " 23,\n",
              " 33,\n",
              " 43,\n",
              " 53,\n",
              " 63,\n",
              " 73,\n",
              " 83,\n",
              " 93,\n",
              " 103,\n",
              " 113,\n",
              " 123,\n",
              " 133,\n",
              " 143,\n",
              " 153,\n",
              " 163,\n",
              " 173,\n",
              " 183,\n",
              " 193,\n",
              " 203,\n",
              " 213,\n",
              " 223,\n",
              " 233,\n",
              " 243,\n",
              " 253,\n",
              " 263,\n",
              " 273,\n",
              " 283,\n",
              " 293,\n",
              " 303,\n",
              " 313,\n",
              " 323,\n",
              " 333,\n",
              " 343,\n",
              " 353,\n",
              " 363,\n",
              " 373,\n",
              " 383,\n",
              " 393,\n",
              " 403,\n",
              " 413,\n",
              " 423,\n",
              " 433,\n",
              " 443,\n",
              " 453,\n",
              " 463,\n",
              " 473,\n",
              " 483,\n",
              " 493,\n",
              " 4,\n",
              " 14,\n",
              " 24,\n",
              " 34,\n",
              " 44,\n",
              " 54,\n",
              " 64,\n",
              " 74,\n",
              " 84,\n",
              " 94,\n",
              " 104,\n",
              " 114,\n",
              " 124,\n",
              " 134,\n",
              " 144,\n",
              " 154,\n",
              " 164,\n",
              " 174,\n",
              " 184,\n",
              " 194,\n",
              " 204,\n",
              " 214,\n",
              " 224,\n",
              " 234,\n",
              " 244,\n",
              " 254,\n",
              " 264,\n",
              " 274,\n",
              " 284,\n",
              " 294,\n",
              " 304,\n",
              " 314,\n",
              " 324,\n",
              " 334,\n",
              " 344,\n",
              " 354,\n",
              " 364,\n",
              " 374,\n",
              " 384,\n",
              " 394,\n",
              " 404,\n",
              " 414,\n",
              " 424,\n",
              " 434,\n",
              " 444,\n",
              " 454,\n",
              " 464,\n",
              " 474,\n",
              " 484,\n",
              " 494,\n",
              " 5,\n",
              " 15,\n",
              " 25,\n",
              " 35,\n",
              " 45,\n",
              " 55,\n",
              " 65,\n",
              " 75,\n",
              " 85,\n",
              " 95,\n",
              " 105,\n",
              " 115,\n",
              " 125,\n",
              " 135,\n",
              " 145,\n",
              " 155,\n",
              " 165,\n",
              " 175,\n",
              " 185,\n",
              " 195,\n",
              " 205,\n",
              " 215,\n",
              " 225,\n",
              " 235,\n",
              " 245,\n",
              " 255,\n",
              " 265,\n",
              " 275,\n",
              " 285,\n",
              " 295,\n",
              " 305,\n",
              " 315,\n",
              " 325,\n",
              " 335,\n",
              " 345,\n",
              " 355,\n",
              " 365,\n",
              " 375,\n",
              " 385,\n",
              " 395,\n",
              " 405,\n",
              " 415,\n",
              " 425,\n",
              " 435,\n",
              " 445,\n",
              " 455,\n",
              " 465,\n",
              " 475,\n",
              " 485,\n",
              " 495,\n",
              " 6,\n",
              " 16,\n",
              " 26,\n",
              " 36,\n",
              " 46,\n",
              " 56,\n",
              " 66,\n",
              " 76,\n",
              " 86,\n",
              " 96,\n",
              " 106,\n",
              " 116,\n",
              " 126,\n",
              " 136,\n",
              " 146,\n",
              " 156,\n",
              " 166,\n",
              " 176,\n",
              " 186,\n",
              " 196,\n",
              " 206,\n",
              " 216,\n",
              " 226,\n",
              " 236,\n",
              " 246,\n",
              " 256,\n",
              " 266,\n",
              " 276,\n",
              " 286,\n",
              " 296,\n",
              " 306,\n",
              " 316,\n",
              " 326,\n",
              " 336,\n",
              " 346,\n",
              " 356,\n",
              " 366,\n",
              " 376,\n",
              " 386,\n",
              " 396,\n",
              " 406,\n",
              " 416,\n",
              " 426,\n",
              " 436,\n",
              " 446,\n",
              " 456,\n",
              " 466,\n",
              " 476,\n",
              " 486,\n",
              " 496,\n",
              " 7,\n",
              " 17,\n",
              " 27,\n",
              " 37,\n",
              " 47,\n",
              " 57,\n",
              " 67,\n",
              " 77,\n",
              " 87,\n",
              " 97,\n",
              " 107,\n",
              " 117,\n",
              " 127,\n",
              " 137,\n",
              " 147,\n",
              " 157,\n",
              " 167,\n",
              " 177,\n",
              " 187,\n",
              " 197,\n",
              " 207,\n",
              " 217,\n",
              " 227,\n",
              " 237,\n",
              " 247,\n",
              " 257,\n",
              " 267,\n",
              " 277,\n",
              " 287,\n",
              " 297,\n",
              " 307,\n",
              " 317,\n",
              " 327,\n",
              " 337,\n",
              " 347,\n",
              " 357,\n",
              " 367,\n",
              " 377,\n",
              " 387,\n",
              " 397,\n",
              " 407,\n",
              " 417,\n",
              " 427,\n",
              " 437,\n",
              " 447,\n",
              " 457,\n",
              " 467,\n",
              " 477,\n",
              " 487,\n",
              " 497,\n",
              " 8,\n",
              " 18,\n",
              " 28,\n",
              " 38,\n",
              " 48,\n",
              " 58,\n",
              " 68,\n",
              " 78,\n",
              " 88,\n",
              " 98,\n",
              " 108,\n",
              " 118,\n",
              " 128,\n",
              " 138,\n",
              " 148,\n",
              " 158,\n",
              " 168,\n",
              " 178,\n",
              " 188,\n",
              " 198,\n",
              " 208,\n",
              " 218,\n",
              " 228,\n",
              " 238,\n",
              " 248,\n",
              " 258,\n",
              " 268,\n",
              " 278,\n",
              " 288,\n",
              " 298,\n",
              " 308,\n",
              " 318,\n",
              " 328,\n",
              " 338,\n",
              " 348,\n",
              " 358,\n",
              " 368,\n",
              " 378,\n",
              " 388,\n",
              " 398,\n",
              " 408,\n",
              " 418,\n",
              " 428,\n",
              " 438,\n",
              " 448,\n",
              " 458,\n",
              " 468,\n",
              " 478,\n",
              " 488,\n",
              " 498,\n",
              " 9,\n",
              " 19,\n",
              " 29,\n",
              " 39,\n",
              " 49,\n",
              " 59,\n",
              " 69,\n",
              " 79,\n",
              " 89,\n",
              " 99,\n",
              " 109,\n",
              " 119,\n",
              " 129,\n",
              " 139,\n",
              " 149,\n",
              " 159,\n",
              " 169,\n",
              " 179,\n",
              " 189,\n",
              " 199,\n",
              " 209,\n",
              " 219,\n",
              " 229,\n",
              " 239,\n",
              " 249,\n",
              " 259,\n",
              " 269,\n",
              " 279,\n",
              " 289,\n",
              " 299,\n",
              " 309,\n",
              " 319,\n",
              " 329,\n",
              " 339,\n",
              " 349,\n",
              " 359,\n",
              " 369,\n",
              " 379,\n",
              " 389,\n",
              " 399,\n",
              " 409,\n",
              " 419,\n",
              " 429,\n",
              " 439,\n",
              " 449,\n",
              " 459,\n",
              " 469,\n",
              " 479,\n",
              " 489,\n",
              " 499]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnoXBl3q-H2v",
        "colab_type": "text"
      },
      "source": [
        "## Joins"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RYUC49k-Jx3",
        "colab_type": "text"
      },
      "source": [
        "Con los joins se combinan dos RDD en base a las claves de los registros. Junta cada registro del primer RDD con cada registro del segundo RDD que tengan la misma clave. No agrupa, sino que es de a pares de registro."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiHtBvLs-ADS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_alumnos = [\n",
        "  (1,'Damian'),\n",
        "  (2,'Luis'),\n",
        "  (3,'Martin'),\n",
        "  (4,'Natalia'),\n",
        "  (5,'Joaquin')\n",
        "]\n",
        "\n",
        "alumnos = sc.parallelize(data_alumnos)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSEG_YQF-sgz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "5376f64d-c76e-4cec-b3d4-99c58caa573c"
      },
      "source": [
        "alumnos.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 'Damian'), (2, 'Luis'), (3, 'Martin'), (4, 'Natalia'), (5, 'Joaquin')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcQnmQOX-v8X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_materias_aprobadas = [\n",
        "  (1, 'Algebra'),\n",
        "  (2, 'Análisis Matemático'),\n",
        "  (200, 'Algebra'),\n",
        "  (2, 'Física')\n",
        "]\n",
        "\n",
        "materias_aprobadas = sc.parallelize(data_materias_aprobadas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DMPmYzl_8HI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "053013f9-c33e-4007-a33a-c423d16f8bae"
      },
      "source": [
        "materias_aprobadas.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 'Algebra'), (2, 'Análisis Matemático'), (200, 'Algebra'), (2, 'Física')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUC97o6nE36O",
        "colab_type": "text"
      },
      "source": [
        "### Inner Join (Join)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fII6Z3hAE8_3",
        "colab_type": "text"
      },
      "source": [
        "Cuando se llama para sets de datos del tipo (K,V) y (K,W) devuelve un set de datos del tipo (K, (V,W)) con todos los pares de elementos para cada key. (especificamente los que hay en comun por esa clave en ambos sets de datos)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flekON_1_9dH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "40c74b5d-d761-4ea8-8f26-a250f32343d4"
      },
      "source": [
        "alumnos.join(materias_aprobadas).collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, ('Damian', 'Algebra')),\n",
              " (2, ('Luis', 'Análisis Matemático')),\n",
              " (2, ('Luis', 'Física'))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pkgFzBWFE5S",
        "colab_type": "text"
      },
      "source": [
        "### Left Outer Join"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7Sd_L-kHLnh",
        "colab_type": "text"
      },
      "source": [
        "Cuando se llama para sets de datos del tipo (K,V) y (K,W) devuelve un set de datos del tipo (K, (V,W)) asegurandonos que todos los datos del set de datos izquierdo estaran en el resultado del join."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2e_wWrASFCbH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "outputId": "07caa638-501f-4288-987e-d0a8a3c7e0b0"
      },
      "source": [
        "alumnos.leftOuterJoin(materias_aprobadas).collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(4, ('Natalia', None)),\n",
              " (1, ('Damian', 'Algebra')),\n",
              " (5, ('Joaquin', None)),\n",
              " (2, ('Luis', 'Análisis Matemático')),\n",
              " (2, ('Luis', 'Física')),\n",
              " (3, ('Martin', None))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL1vuNozHWf2",
        "colab_type": "text"
      },
      "source": [
        "### Right Outer Join"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJs-3temHYiM",
        "colab_type": "text"
      },
      "source": [
        "Cuando se llama para sets de datos del tipo (K,V) y (K,W) devuelve un set de datos del tipo (K, (V,W)) asegurandonos que todos los datos del set de datos derecho estaran en el resultado del join."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWgbjDenHRXa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "c7756b19-cff0-4326-ac5b-fa8dc4d94de5"
      },
      "source": [
        "alumnos.rightOuterJoin(materias_aprobadas).collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(200, (None, 'Algebra')),\n",
              " (1, ('Damian', 'Algebra')),\n",
              " (2, ('Luis', 'Análisis Matemático')),\n",
              " (2, ('Luis', 'Física'))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5dKB2iQHhZX",
        "colab_type": "text"
      },
      "source": [
        "### Outer/Full Join"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ow57N52-HlDu",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Cuando se llama para sets de datos del tipo (K,V) y (K,W) devuelve un set de datos del tipo (K, (V,W)) asegurandonos que todos los datos de ambos set de datos estaran aunque no haya match de keys."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xUS95vzHdkw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "209d24cb-09fb-488f-b7c8-d67b5f8cec2d"
      },
      "source": [
        "alumnos.fullOuterJoin(materias_aprobadas).collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(4, ('Natalia', None)),\n",
              " (200, (None, 'Algebra')),\n",
              " (1, ('Damian', 'Algebra')),\n",
              " (5, ('Joaquin', None)),\n",
              " (2, ('Luis', 'Análisis Matemático')),\n",
              " (2, ('Luis', 'Física')),\n",
              " (3, ('Martin', None))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AieykhPHthx",
        "colab_type": "text"
      },
      "source": [
        "### Broadcast Join (map-side join)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULF_l_PKHvoT",
        "colab_type": "text"
      },
      "source": [
        "#### Variable Broadcast"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rm6ouls5H2iG",
        "colab_type": "text"
      },
      "source": [
        "Una variable Broadcast nos permite mantener una variable solo lectura cacheada en cada una de las maquinas del cluster en vez de enviar esa informacion con cada una de las tareas que se envian al cluster.\n",
        "\n",
        "Esto es particularmente util cuando cuando tareas a partir de multiples etapas (stages) necesitan la misma información o cuando cachear información de forma deserializada es importante.\n",
        "\n",
        "Tener en cuenta que esto **es posible** cuando uno de los data sets o conjunto de datos **es lo suficientemente pequeño para ser broadcasteado a todos los nodos/workers del cluster**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_XZYCyZHpA9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Vamos a suponer que tenemos un RDD de productos por sus IDs identificando ventas de los mismos\n",
        "prodsList = [1,11,1,4,5,11,2,3,4,5,6,4,5,4,3,2,1,11,2,3,4,5,6,4,3,2,1,1]\n",
        "prods = sc.parallelize(prodsList,3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqKNAzbUIInc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Un hash con los productos y sus nombres\n",
        "productNames = {1:'papas',\n",
        "                2:'cebollas',\n",
        "                3:'tomates',\n",
        "                4:'zanahorias',\n",
        "                5:'batatas',\n",
        "                6:'peras',\n",
        "                7:'cilantro',\n",
        "                8:'apio',\n",
        "                9:'morrones',\n",
        "                10:'manzanas',\n",
        "                11:'naranjas'}\n",
        "\n",
        "# Hacemos un broadcast de la variable\n",
        "bproductNames = sc.broadcast(productNames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbtkGuPuIQVI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "f0d8a789-f32e-4d72-df54-d1336cf9a1c8"
      },
      "source": [
        "# Buscamos los productos que se vendieron más de 4 veces\n",
        "popularProds = prods.map(lambda x:(x,1))\\\n",
        "    .reduceByKey(lambda x,y:x+y)\\\n",
        "    .filter(lambda x:x[1]>=4)\n",
        "popularProds.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(3, 4), (1, 5), (4, 6), (5, 4), (2, 4)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atJ07Q64Idvx",
        "colab_type": "text"
      },
      "source": [
        "El join se realiza de forma implicita usando un map y dentro del mismo accediendo a la informacion de la variable a la que se realizo el broadcast via .value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rq0QI5QWIWNL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "6c212f71-bcd6-4a2a-93a3-6ad4ed036305"
      },
      "source": [
        "popularProds = popularProds.map(\n",
        "    lambda x:(bproductNames.value[x[0]],x[0],x[1]))\n",
        "popularProds.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('tomates', 3, 4),\n",
              " ('papas', 1, 5),\n",
              " ('zanahorias', 4, 6),\n",
              " ('batatas', 5, 4),\n",
              " ('cebollas', 2, 4)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-saIXIYOJJwA",
        "colab_type": "text"
      },
      "source": [
        "#### Ventajas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GemDSZwrJSXS",
        "colab_type": "text"
      },
      "source": [
        "Cuando un valor es \"broadcasteado\" al cluster, este es copiado a los nodos/workers **sólo una vez** (en vez de múltiples veces si la información fuera a enviarse en cada task). De esta forma se resuelve la consulta más rapidamente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5T0HkWAN-Iw",
        "colab_type": "text"
      },
      "source": [
        "# 6-Transformaciones sobre las particiones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RopZZdNOJGvQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "a65ea279-27b1-4940-a9b6-2cc7923e47af"
      },
      "source": [
        "rdd = sc.parallelize(range(1,11))\n",
        "rdd.getNumPartitions()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnvORFhIOKqk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "cec40e0c-a554-407d-f1cb-acde2eaffe28"
      },
      "source": [
        "sc.defaultParallelism"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vt6pb_QhAQOC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "d05e8f41-acae-4af4-8178-bc03be2e8b6e"
      },
      "source": [
        "rdd.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dh3FU26O_zFD",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjMa0g_i99y5",
        "colab_type": "text"
      },
      "source": [
        "## Glom"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJngJqoI-Uez",
        "colab_type": "text"
      },
      "source": [
        "Junta los registros de cada partición en una lista."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_ONKwAMOPgN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "e4ee89e4-23d3-491b-9105-4a36f33b3f23"
      },
      "source": [
        "rdd.glom().collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQqRRZf4-sZ3",
        "colab_type": "text"
      },
      "source": [
        "## MapPartitions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6eW2l3O-v_4",
        "colab_type": "text"
      },
      "source": [
        "Devuelve un nuevo RDD aplicando una función a cada partición del RDD."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zh8cyhDeOTUX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "92744df7-b073-4ea4-84ba-4c22e9ecb900"
      },
      "source": [
        "def f(iterator): yield __builtin__.sum(iterator)\n",
        "rdd.mapPartitions(f).collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[15, 40]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBW1VMB5RdOr",
        "colab_type": "text"
      },
      "source": [
        "## Repartition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svqGE-d7RoSp",
        "colab_type": "text"
      },
      "source": [
        "Reshuffle los datos en el RDD de forma aleatoria para crear más o menos particiones y balancearlas. \n",
        "\n",
        "Hace un shuffle de todo los datos por la red."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mV5EaYhScbs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "6adb841b-1059-4add-8d61-ae4198439724"
      },
      "source": [
        "rdd = sc.parallelize(range(1,11), 4)\n",
        "rdd.getNumPartitions()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOcEeb93SpmS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "9d054e32-3dd8-4938-a6b7-e5948784b35c"
      },
      "source": [
        "rdd.glom().collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 2], [3, 4, 5], [6, 7], [8, 9, 10]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIm6FX5fPYzw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rdd2 = rdd.repartition(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d44SVE6PSH9N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "3d7daf0d-cc2a-4846-bc52-d471565b4ec9"
      },
      "source": [
        "rdd2.getNumPartitions()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txLaGMBXSItl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "d0b1dff3-5ca5-4ac2-eb95-7cea0c59c106"
      },
      "source": [
        "rdd2.glom().collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 2, 6, 7, 8, 9, 10], [3, 4, 5]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YX-bJjSOTFXA",
        "colab_type": "text"
      },
      "source": [
        "Spark no hace shuffle de registros individuales sino de a bloques con un mínimo (no es un problema cuando se manejan grandes cantidades de datos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "md7oT6F7T-N6",
        "colab_type": "text"
      },
      "source": [
        "## Coalesce"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6nPKD5pUK6g",
        "colab_type": "text"
      },
      "source": [
        "Decrementa la cantidad de particiones del RDD.\n",
        "\n",
        "No hace shuffle por defecto, solo pasa datos de una partición a otra.\n",
        "\n",
        "No quedan balanceadas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5jxQeUUSQZJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rddCoalesce = rdd.coalesce(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijvk00kuUfs1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "27cfb0c1-f6b1-46cd-933c-52ff327fdf32"
      },
      "source": [
        "rddCoalesce.glom().collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNP1bHnPVCfV",
        "colab_type": "text"
      },
      "source": [
        "## RepartitionAndSortWithinPartitions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3i7Du_xtbrwG",
        "colab_type": "text"
      },
      "source": [
        "Reparticiona un RDD de acuerdo a un particionador y ordena los registros en base a su clave.\n",
        "\n",
        "Los registros deben tener clave.\n",
        "\n",
        "Es más eficiente que hacer un repartition y luego un sort dentro de cada partición ya que realiza el sort en el mismo paso de shuffle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMkGtQYYUjXJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "de2074a1-6d8c-467d-c2af-e8675e473f3c"
      },
      "source": [
        "rdd.map(lambda x: (x, x)).collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 1),\n",
              " (2, 2),\n",
              " (3, 3),\n",
              " (4, 4),\n",
              " (5, 5),\n",
              " (6, 6),\n",
              " (7, 7),\n",
              " (8, 8),\n",
              " (9, 9),\n",
              " (10, 10)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVPrXSV0XiUe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "8b08c90c-2a4e-4706-a9f9-7aaef571c5aa"
      },
      "source": [
        "rdd.map(lambda x: (x, x)).glom().collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[(1, 1), (2, 2)],\n",
              " [(3, 3), (4, 4), (5, 5)],\n",
              " [(6, 6), (7, 7)],\n",
              " [(8, 8), (9, 9), (10, 10)]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKEX0nqDca0X",
        "colab_type": "text"
      },
      "source": [
        "### Ascending"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cy7qnMGKXbBC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "5bc20e10-590d-4db5-c56a-0b92702372a7"
      },
      "source": [
        "rdd.map(lambda x: (x, x)).repartitionAndSortWithinPartitions(2).glom().collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[(2, 2), (4, 4), (6, 6), (8, 8), (10, 10)],\n",
              " [(1, 1), (3, 3), (5, 5), (7, 7), (9, 9)]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rK68D2aX1fk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "51bfe01d-701d-4844-b5a6-347f814fc6ed"
      },
      "source": [
        "rdd.map(lambda x: (x % 3, x)).repartitionAndSortWithinPartitions(2).glom().collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[(0, 3), (0, 6), (0, 9), (2, 2), (2, 5), (2, 8)],\n",
              " [(1, 1), (1, 4), (1, 7), (1, 10)]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9smRZScuYD8s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "3f4f184a-f9c4-45ad-99f7-3f1f42246f7d"
      },
      "source": [
        "rdd.map(lambda x: (x % 3, x)).repartitionAndSortWithinPartitions(2, ascending=False).glom().collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[(2, 2), (2, 5), (2, 8), (0, 3), (0, 6), (0, 9)],\n",
              " [(1, 1), (1, 4), (1, 7), (1, 10)]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUyetYoZceNB",
        "colab_type": "text"
      },
      "source": [
        "### PartitionFunc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1xwWifQYT9r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "3f016008-26bd-4f52-f777-0c97998a6358"
      },
      "source": [
        "rdd.map(lambda x: (x * 2, x)).repartitionAndSortWithinPartitions(2).glom().collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[(2, 1),\n",
              "  (4, 2),\n",
              "  (6, 3),\n",
              "  (8, 4),\n",
              "  (10, 5),\n",
              "  (12, 6),\n",
              "  (14, 7),\n",
              "  (16, 8),\n",
              "  (18, 9),\n",
              "  (20, 10)],\n",
              " []]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDsh3YFLYmel",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "3e4186b5-5049-4e98-dd27-dff589e320dd"
      },
      "source": [
        "rdd.map(lambda x: (x * 2, x)).repartitionAndSortWithinPartitions(2, partitionFunc=lambda x: (x % 3)).glom().collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[(2, 1), (6, 3), (8, 4), (12, 6), (14, 7), (18, 9), (20, 10)],\n",
              " [(4, 2), (10, 5), (16, 8)]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynV8o0DQe-hS",
        "colab_type": "text"
      },
      "source": [
        "# 7-Persistiendo RDD (Persistencia y CACHE)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "py6LcfQ3fDHc",
        "colab_type": "text"
      },
      "source": [
        "## Cache"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKoTPP8DfFYm",
        "colab_type": "text"
      },
      "source": [
        "Cachea un RDD intermedio que va a ser utilizado varias veces de modo de evitar tener que ejecutar todas las transformaciones cada vez."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7T8S272Idj6g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rdd = sc.parallelize(range(1,100000))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nz4CC4u9d43K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rddCached = rdd.map(lambda x: x*10).cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYQ74fKfeCiY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "24d56723-5e27-45d0-a2bc-f965df83c3b9"
      },
      "source": [
        "rddCached.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "99999"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i27r47iieEHg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "0731aea1-a598-4f3b-eb3d-6e62b2dbbb97"
      },
      "source": [
        "rddCached.take(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[10, 20, 30, 40, 50, 60, 70, 80, 90, 100]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-w0puPNfe5u",
        "colab_type": "text"
      },
      "source": [
        "## SaveAsTextFile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0n6xyV5fiY1",
        "colab_type": "text"
      },
      "source": [
        "Guarda un RDD a disco en un archivo de texto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFBypm_3dU15",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rdd.saveAsTextFile('numbers.txt')  #Podemos indicar la ruta acá tambien."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BB6t8lSdW_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rddN = sc.textFile('numbers.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThBA5KkEdidg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 800
        },
        "outputId": "c5cff3c4-7be1-47d5-c633-611ed9a35362"
      },
      "source": [
        "rddN.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Py4JJavaError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-159-484df78fbdae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrddN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \"\"\"\n\u001b[1;32m    888\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: file:/content/numberss.txt\n\tat org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:287)\n\tat org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:229)\n\tat org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:315)\n\tat org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:205)\n\tat org.apache.spark.rdd.RDD.$anonfun$partitions$2(RDD.scala:276)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:272)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:49)\n\tat org.apache.spark.rdd.RDD.$anonfun$partitions$2(RDD.scala:276)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:272)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2158)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1004)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:388)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1003)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:168)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98_lZqcufocO",
        "colab_type": "text"
      },
      "source": [
        "## SaveAsPickleFile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uoTsAuIf1hG",
        "colab_type": "text"
      },
      "source": [
        "Guarda un RDD a disco en un archivo con los datos serializados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EE_YrGrEeGaq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rdd.saveAsPickleFile('numbers2.file')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ol9nG9vdej3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rddN2 = sc.pickleFile('numbers2.file')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAOGcsPge2r6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "afdd6790-cc94-4cb9-e921-68cdd05aaf4b"
      },
      "source": [
        "rddN2.take(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    }
  ]
}